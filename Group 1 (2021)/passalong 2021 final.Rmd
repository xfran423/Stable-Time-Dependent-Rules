---
title: "Passalong_2021_final"
author: "Xavier Francis"
date: "2024-03-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




#Load packages
```{r}
library(readr)
library(dplyr)
library(tidyr)
library(data.table) 
library(ggplot2)
library(chemodiv)
library(introdataviz)
library(lme4)
library(multcomp)
library(sjPlot)
library(emdist)


```


#observed rule follows
```{r}
#start with both_numbered_sorted

#ensure that ranks are numeric
both_numbered_sorted$actor_rank <- as.numeric(both_numbered_sorted$actor_rank)
both_numbered_sorted$subject_rank <- as.numeric(both_numbered_sorted$subject_rank)

head(both_numbered_sorted)


#procedure to add obs session

#store the first row as a separate df. It will be binded back on later 
row_1_obs <- both_numbered_sorted[1,]

#put events side by side. This will allow us to subtract consecutive times from one another to determine whether an event took place on a separate observation session. 
obs_period_pt_1 <- mutate(both_numbered_sorted, actor_2 = lead(actor),
actor_2_rank = lead(actor_rank), 
subject_2 = lead(subject),                                   
subject_2_rank = lead(subject_rank), 
 full_time_2 = lead(full_time), 
date2 = lead(date))

#add empty columns for observation period and date period
obs_period_pt_1$obs_period <- NA
obs_period_pt_1$date_period <- NA

#create ticker for loop
q <- 1

#loop to calculate observation sessions. If consecutive events were on the same day but there was a long time between events, it is determined that the 2nd event took place in a separate observation session. The ticker goes up, and is reset if events took place on different days.
for (i in 1:nrow(obs_period_pt_1)) {ifelse(obs_period_pt_1$date[i] == obs_period_pt_1$date2[i]
                                            & obs_period_pt_1$full_time_2[i] - obs_period_pt_1$full_time[i] >= 1800, q <- q+1, q <- q)
  ifelse(obs_period_pt_1$date[i] != obs_period_pt_1$date2[i], q <- 1, q <- q)
  obs_period_pt_1$obs_period [i] <- q
  }

#remove original columns and keep mutated columns. These will replace original columns
obs_period_pt_2 <- subset(obs_period_pt_1, select = c(date2,  full_time_2, actor_2, actor_2_rank, subject_2, subject_2_rank, obs_period, date_period  ))

#get rid of the bottom, which will be full of NAs, as the last event in the original data does not have anything that comes after
obs_period_pt_3 <- slice(obs_period_pt_2, 1:(n() - 1))

#rename mutated columns with original names 
setnames(obs_period_pt_3, old = c('date2',  'full_time_2', 'actor_2', 'actor_2_rank', 'subject_2', 'subject_2_rank'), 
         new = c('date',  'full_time', 'actor', 'actor_rank', 'subject', 'subject_rank'))

#add observation period "1" onto first row that we subseted off, as the first event in the data has to take place in obs session 1
row_1_obs$obs_period <- 1 
row_1_obs$date_period <- NA

#ensure that row 1 matches the df
row_1_obs_ready <-  subset(row_1_obs, select = c(date,  full_time, actor, actor_rank, subject, subject_rank, obs_period, date_period  ))

#bind first row and df together
obs_period_pt_4 <- rbind(row_1_obs_ready, obs_period_pt_3)
#add date period 
obs_period_pt_4$date_period <- paste(obs_period_pt_4$date,obs_period_pt_4$obs_period)
head(obs_period_pt_4)

```


```{r}

date_x <- obs_period_pt_4$date
obs <- obs_period_pt_4$date_period
#separate data into a list with each df=a date so we can randomize within days
#sort_by_date <- function(x, i, y) {y <- filter(x, date == i )
#mutate(y, date_counter = i)}


#list of dataframes where each dataframe has a certain birdname isolated as actor or recipient
pass_along_aggression_list <- list()


dater <- unique(obs)
datex <- c(1: length(unique(obs)))
actorer <- actor
actex <- c(1:length(actor))




#separate data into list of each obs session each day for each bird
for(i in datex) { 
  for (g in actex){
    output <- filter(obs_period_pt_4, obs_period_pt_4$date_period == dater[i] & (subject == actorer[g] | actor == actorer[g]))
    if (nrow(output) < 1) {output [ nrow(output) + 1 , ] <- NA
    } 
    output <- mutate(output, counter = actorer[g])
    pass_along_aggression_list[[paste0("list", dater[i], actorer[g])]] <- output}}






#ensure df arranged by date and time
pass_along_aggression_list <- lapply(pass_along_aggression_list, function(x) arrange(x, date, full_time))

#modified data frame to put consecutive events side by side

pass_along_side_by_side <- lapply(pass_along_aggression_list, function(x) mutate(x, actor_2 = lead(actor), 
                                                                                 actor_2_rank = lead(actor_rank), 
                                                                                 subject_2 = lead(subject), 
                                                                                 subject_2_rank = lead(subject_rank), 
                                                                                 full_time_2 = lead(full_time), 
                                                                                 date2 = lead(date))) 


dateact1 <-  c(1:length(pass_along_side_by_side))


#pick out pass along rule while keeping all dataframes in a list (yay!!!)
for(i in dateact1 ) {
  pass_along_side_by_side[[i]] <- mutate(pass_along_side_by_side[[i]], 
                                         initiated = ifelse(subject == counter, "yes","no"), 
                                         rule_followed = ifelse( subject == actor_2 
                                                                 & full_time_2 - full_time <= 336 
                                                                 & full_time_2 - full_time > 0
                                                                 & date2 == date
                                                                 & subject == counter
                                                                 & actor_2 == counter
                                                                 & actor_2_rank < subject_2_rank
                                                                 & actor != subject_2,
                                                                 "yes","no"))
} 




#combine dataframes into one huge dataframe
pass_along_huge <- bind_rows(pass_along_side_by_side, .id = "column_label")

#sort by time and date
pass_along_huge_sorted <- pass_along_huge %>%
  arrange(pass_along_huge$date, pass_along_huge$full_time)

#Remove duplicate events, events that have been represented twice, and events that could not confidently be counted as the start of pass-along
pass_along_huge_sorted_no_dupr <- subset(pass_along_huge_sorted, initiated != "no") 

#subset for desired columns
pass_along_no_dupr <- subset(pass_along_huge_sorted_no_dupr, select = c(date, full_time, actor, actor_rank, subject, subject_rank,  
                                                                                   counter, actor_2, actor_2_rank, subject_2, subject_2_rank, full_time_2, date2, 
                                                                                   initiated, rule_followed))
                             
table(pass_along_no_dupr$rule_followed)


 #determine how many times rule was followed
pass_along_real_2021 <- length(which(pass_along_no_dupr$rule_followed == "yes"))

pass_along_real_frame_2021 <- data.frame(pass_along_real_2021)


 #create df of only rule follows
pass_along_doner_all_yes <-filter(pass_along_no_dupr, rule_followed == "yes")


```
#Test for individual rule use
```{r}


#test for individual use of rule. How many times did each bird use rule
unique(pass_along_doner_all_yes$actor_2)
length(unique(pass_along_doner_all_yes$actor_2)
)

summary.pass.individ_2021 <- pass_along_doner_all_yes %>% group_by(actor_2) %>%
  dplyr::summarize (
    count =n())

summary.pass.individ_2021





#show Liz
#unique(`2021_interactions_cleaned`$actor)


#compare to raw dataset to see if any birds didnt use rule at all
unique(t2021_aggression_only_ready$actor)
unique(t2021_aggression_only_ready$subject)




#for each rule keep in mind how many birds can actually use the rule
#bird who didnt do rule was bottom ranked and cant do rule
pass_along_nofollow <- setdiff(unique(t2021_aggression_only_ready$actor), unique(pass_along_doner_all_yes$actor_2)
)
pass_along_nofollow



#Calculate Richness score for rule following
#DO FIRST BEFORE ADDING ZEROS AND DONT DO AGAIN WITHOUT RUNNING ABOVE CODE
#Calculate Richness score for rule following
pass_along_richness <- length(summary.pass.individ_2021$actor_2)/18
#remember to remove birds that cant do rule for next chap
#########################################################
##########################################################

#add in 0s for individuals who did not follow rule for plotting purposes
pass_along_zeros <- rep(c(0),times=c(length(pass_along_nofollow)))


pass_along_nofollow_zeros<- data.frame(pass_along_nofollow,pass_along_zeros) 

colnames(pass_along_nofollow_zeros) <- c("actor_2","count")

summary.pass.individ_2021 <- rbind(summary.pass.individ_2021, pass_along_nofollow_zeros)

# Plot
individ_pass_plot_2021 <- ggplot(summary.pass.individ_2021, aes(x = actor_2, y = count )) + 
  geom_bar(stat = "identity", width = 0.6) + # Consistent bar width
scale_y_continuous( breaks = seq(0, 60, 2)) + 
  theme_minimal()  +
  theme(
    axis.text.x = element_text(angle = 90, vjust=0.5),
    axis.title.x = element_text( face = "bold",  margin = margin(t = 15)),  # X-axis title
    axis.title.y = element_text( face = "bold",  margin = margin(r = 15)),
    ) +
  labs(
    x = "Parakeet ID",  # Add your custom x-axis title here
    y = "Count of rule follows"   # Add your custom y-axis title here
  )

individ_pass_plot_2021
#Calculate eveness metric
pass_for_even <- subset(summary.pass.individ_2021, select = c(count))

final_pass_for_even <- as.data.frame(t(pass_for_even))

pass_even_value <-calcDiv(final_pass_for_even, type = "PielouEven", q = 1) 

pass_even_value

```


#test for length of passalong
```{r}

########################################################################################################
#test for length of passalong


#follows similar procedure as calculating the count of rule follows, with some differences in the rule detection loop and the structure

#put df side by side
pass_along_side_by_side_time <- lapply(pass_along_aggression_list, function(x) mutate(x, actor_2 = lead(actor), 
                                                                                      actor_2_rank = lead(actor_rank), 
                                                                                      subject_2 = lead(subject), 
                                                                                      subject_2_rank = lead(subject_rank), 
                                                                                      full_time_2 = lead(full_time), 
                                                                                      date2 = lead(date))) 





#test for length of pass-alongs in seconds
for(i in dateact1) {
  pass_along_side_by_side_time[[i]] <- mutate(pass_along_side_by_side_time[[i]], 
                                              initiated = ifelse(subject == counter, "yes","no"), 
                                              rule_followed = ifelse( subject == actor_2 
                                                                      & date2 == date
                                                                      & subject == counter
                                                                      & actor_2 == counter
                                                                      & actor_2_rank < subject_2_rank
                                                                      & full_time_2 - full_time > 0
                                                                      & actor != subject_2,
                                                                      "yes","no"),
                                              time_to_pass = full_time_2 - full_time)
} 

#bind list of dfs into one df
pass_along_huge_time <- bind_rows(pass_along_side_by_side_time, .id = "column_label")

#sort by time and date
pass_along_huge_sorted_time <- pass_along_huge_time %>%
  arrange(pass_along_huge_time$date, pass_along_huge_time$full_time)


#remove any duplicate or double counted events 
pass_along_huge_sorted_no_dupr_time <- subset(pass_along_huge_sorted_time, initiated != "no") 

#subset for columns of interest
pass_along_no_dupr_time <- subset(pass_along_huge_sorted_no_dupr_time, select = c(date, full_time, actor, actor_rank, subject, subject_rank,  
                                                                                  counter, actor_2, actor_2_rank, subject_2, subject_2_rank, full_time_2, date2, 
                                                                                  initiated, rule_followed, time_to_pass, date_period))



#get df where rule was followed
pass_length <- subset(pass_along_no_dupr_time, rule_followed != "no")

#subset for columns of interest
pass_length_ready <- subset( pass_length, select = c(time_to_pass, actor, subject, actor_2, subject_2, date_period))

p <- length(pass_length_ready$time_to_pass)

#summarize the speed of rule follows. Here we are checking whether the speed of the rule in question tends to be clustered
summary.pass <- pass_length_ready %>% group_by(time_to_pass) %>%
  dplyr::summarize (
    count =n())


summary.pass


#quick glimpses of the distribution of rule speeds
ggplot(pass_length_ready, aes(x=time_to_pass)) + 
  geom_histogram(aes(y=..density..),      
                 binwidth=50,
                 colour="black", fill="white") + 
  geom_density()




ggplot(pass_length_ready, aes(x=time_to_pass)) + 
  geom_histogram(aes(y=..density..),      
                 binwidth=10,
                 colour="black", fill="white") + 
  geom_density() +   scale_x_continuous(name = "length in s of pass along events", limits = c(0,3000)) 


```



#Permutation to randomize order of events
```{r}

#################################################loop#################################################################

#start with "both_numbered_sorted"

head(both_numbered_sorted)


#procedure to randomize within obs sesh
#store first row
row_1_obs <- both_numbered_sorted[1,]

#put events side by side. This will allow us to subtract consecutive times from one another to determine whether an event took place on a separate observation session.
obs_period_pt_1 <- mutate(both_numbered_sorted, actor_2 = lead(actor),
                          actor_2_rank = lead(actor_rank), 
                          subject_2 = lead(subject),                                   
                          subject_2_rank = lead(subject_rank), 
                          full_time_2 = lead(full_time), 
                          date2 = lead(date))



#add empty columns for observation period and date period
obs_period_pt_1$obs_period <- NA
obs_period_pt_1$date_period <- NA

#create ticker for loop
q <- 1

#loop to calculate observation sessions. If consecutive events were on the same day but there was a long time between events, it is determined that the 2nd event took place in a separate observation session. The ticker goes up, and is reset if events took place on different days.
for (i in 1:nrow(obs_period_pt_1)) {ifelse(obs_period_pt_1$date[i] == obs_period_pt_1$date2[i]
                                            & obs_period_pt_1$full_time_2[i] - obs_period_pt_1$full_time[i] >= 1800, q <- q+1, q <- q)
  ifelse(obs_period_pt_1$date[i] != obs_period_pt_1$date2[i], q <- 1, q <- q)
  obs_period_pt_1$obs_period [i] <- q
  }

#remove original columns and keep mutated columns. These will replace original columns
obs_period_pt_2 <- subset(obs_period_pt_1, select = c(date2,  full_time_2, actor_2, actor_2_rank, subject_2, subject_2_rank, obs_period, date_period  ))

#get rid of the bottom, which will be full of NAs, as the last event in the original data does not have anything that comes after
obs_period_pt_3 <- slice(obs_period_pt_2, 1:(n() - 1))

#rename mutated columns with original names 
setnames(obs_period_pt_3, old = c('date2',  'full_time_2', 'actor_2', 'actor_2_rank', 'subject_2', 'subject_2_rank'), 
         new = c('date',  'full_time', 'actor', 'actor_rank', 'subject', 'subject_rank'))

#add observation period "1" onto first row that we subseted off, as the first event in the data has to take place in obs session 1
row_1_obs$obs_period <- 1 
row_1_obs$date_period <- NA

#ensure that row 1 matches the df
row_1_obs_ready <-  subset(row_1_obs, select = c(date,  full_time, actor, actor_rank, subject, subject_rank, obs_period, date_period  ))

#bind first row and df together
obs_period_pt_4 <- rbind(row_1_obs_ready, obs_period_pt_3)
#add date period 
obs_period_pt_4$date_period <- paste(obs_period_pt_4$date,obs_period_pt_4$obs_period)



obs <- obs_period_pt_4$date_period
#separate data into a list with each df=a date period so we can randomize within days and obs periods

datelist <- list()
dater <- unique(obs)
datex <- c(1: length(unique(obs)))

#loop to create a separate dataframe for of each obs session each day 
#Each dataframe is stored within a list to make the dataframes easy to work with
#We wish to conserve our permutation randomization within days and, more specifically, within observation sessions
for(i in datex) { 
  output <- filter(obs_period_pt_4, obs_period_pt_4$date_period == dater[i] )
   if (nrow(output) < 1) {output [ nrow(output) + 1 , ] <- NA
    } 
      datelist[[paste0("list", dater[i])]] <- output}




#run ids should be 1 through however many times you want to run through the permutation. Here 1000 times
runIDs <- seq(1,1000)

#create an empty masterframe to be filled with each run of the permutation
masterframe_passalong.df <- data.frame(runIDs = character(),
                                         actor = character(),
                                         subject = character(),
                                         date = character(),
                                         full_time = integer(),
                                         counter = character(),
                                         actor_2 = character(),
                                         subject_2 = character(),
                                         full_time_2 = integer(),
                                         date2 = character(),
                                         initiated = character(),
                                         rule_followed = character(),
                                         stringsAsFactors=FALSE)

nruns <- 1000
#create progress bar
pb <- txtProgressBar(min=0, max = nruns, style = 3)
#seed for no restriction = 11
#seed for 8 sec = 84
#seed for 85 sec =720
#seed for 336 = 52
set.seed(52)#set seed

#forloop starts here'
for (r in 1:length(runIDs)) { #r = 1 is a test you can uncomment to see if it works before #running it 100 times
  #r = 1
    setTxtProgressBar(pb, r) #update progress bar
  run <- r
  loop.run <- paste("run", run) 
  loop.run
  #for example, if r = 1, looprun will say run 1 which will allow you to keep each run's #data straight
  
  
  #loop.seed <- set.seed[r] didnt work so ignore. not needed
  
  
  #renamed data
  loop.datalist <- datelist
  head(loop.datalist[[3]])
  xorder <- c()
  listlength <- as.numeric(length(loop.datalist))
  datex2 <- 1:listlength
  full_time_list <-c()
  loop.data.randomized.time.added <- c()
  #get rid of anything thats not actor and receiver (we will bind back on the date and time #later anyways to preserve
  #their order)
  


   for(i in datex2) {
     #store time
     full_time_list[[i]] <- subset(loop.datalist[[i]], select = c(full_time))
     #remove time from each df in the list. randomizing the order of time wouldnt make sense
     loop.datalist[[i]] <- subset(loop.datalist[[i]], select = -c(full_time))

      #create a randomized sequence of numbers to bind to the subset data (ex. 2,6,1,3,5,4)
      #sort the data frame to put the randomized numbers in order from 1 to whatever and voila, the order of events has been randomized (ex.  from above 1,2,3,4,5,6)
    xorder[[i]] <- data.frame(xorder = sample(1:length(loop.datalist[[i]]$actor),
                                              length(loop.datalist[[i]]$actor)))
    #bind random order to df
    loop.datalist[[i]] <- mutate(loop.datalist[[i]], 
                                 xorderx = xorder[[i]]$xorder)
    #put randomized order of numbers in order to randomize rows in the dataset
    loop.datalist[[i]] <-
      loop.datalist[[i]][order(loop.datalist[[i]]$xorderx),]
    #bind time back on
    loop.data.randomized.time.added[[i]] <- bind_cols(loop.datalist[[i]], full_time_list[[i]])
    loop.data.randomized.time.added[[i]] <- subset(loop.data.randomized.time.added[[i]], select = -c(xorderx))

   }
  
  
#separate data into list of each obs session each day for each bird
actorer <- actor
actex <- c(1:length(actor))
dater <- unique(obs)
list_split_by_bird <- c()

for(i in datex2) {
for (g in actex) {output <- subset(loop.data.randomized.time.added[[i]], actor == actorer[g] |  subject == actorer[g])
   #if one of the dfs in the list is empty, add NA
if (nrow(output) < 1) {output [ nrow(output) + 1 , ] <- NA
    } 
  output <- mutate(output, counter = actorer[g])
  list_split_by_bird[[paste0("list", dater[i], actorer[g])]] <- output
}}

 
  #arrange df by time and date
list_split_by_bird <- lapply(list_split_by_bird, function(x) arrange(x, date, full_time))


#rename df
 pass_along_aggression_list <- list_split_by_bird

  
  
  #modified each data frame to put consecutive events side by side
  pass_along_side_by_side <- lapply(pass_along_aggression_list, function(x) mutate(x, actor_2 = lead(actor), 
                                                                                   actor_2_rank = lead(actor_rank), 
                                                                                   subject_2 = lead(subject), 
                                                                                   subject_2_rank = lead(subject_rank), 
                                                                                   full_time_2 = lead(full_time), 
                                                                                   date2 = lead(date))) 
  
  
  
  
  
  
  head(pass_along_side_by_side[["1"]])
  
  

#loop to set conditionals to pick out passalong

#counter corresponds with which birds dataframe I am looking at and is used to control for false positives 
#for example, if passalong is detected for a bird A whos specific dataframe I am not looking at (im viewing bird Bs df) , this may be a false positive, as that bird A's interactions are not all listed in the dataframe of another bird B. In other words, bird A may have done something else to another bird (C, D, F etc.) that is not listed, as it would be only listed in that specific birds dataframe, that being Bird A's own dataframe 
  for(i in dateact1) {
    pass_along_side_by_side[[i]] <- mutate(pass_along_side_by_side[[i]], 
                                           initiated = ifelse(subject == counter, "yes","no"), 
                                           rule_followed = ifelse( subject == actor_2 
                                                                   & full_time_2 - full_time  <= 336 
                                                                   & full_time_2 - full_time > 0
                                                                   & date2 == date
                                                                   & subject == counter
                                                                   & actor_2 == counter
                                                                   & actor_2_rank < subject_2_rank
                                                                   & actor != subject_2,
                                                                   "yes","no"))
  } 
  
  
  
  
  #combine dataframes into one huge dataframe
  pass_along_huge <- bind_rows(pass_along_side_by_side, .id = "column_label")
  
  #sort by time and date
  pass_along_huge_sorted <- pass_along_huge %>%
    arrange(pass_along_huge$date, pass_along_huge$full_time)
  
  
 #Remove duplicate events, events that have been represented twice, and events that could not confidently be counted as the start of passalong
  pass_along_huge_sorted_no_dup <- subset(pass_along_huge_sorted, initiated != "no") 
  
  pass_along_no_dup <- subset(pass_along_huge_sorted_no_dup, select =  c(actor, actor_rank, subject, subject_rank, date, full_time, 
                                                                         counter, actor_2, actor_2_rank, subject_2, 
                                                                         subject_2_rank, full_time_2, date2, 
                                                                         initiated, rule_followed))

  
  
  #bind vector of run IDs for each run to the dataframe so that you can have a numeric run #id next to each data point
  #that coresponds with that run which will allow you to sort/put them in ascending order later
  runIDs <- rep(loop.run, length(pass_along_no_dup$actor))
  
  passalong_complete <- cbind(runIDs, pass_along_no_dup)
  
  masterframe_passalong.df  <- rbind(masterframe_passalong.df, passalong_complete)
}

#######################################################LOOP#END#######################################################
#write.csv(masterframe_passalong.df, "C:/Users/Xmanf/Desktop/Ch1 TDR files/passalong2021countmaster_336sec.csv")


```


#test observed vs randomzied rule follows
```{r}

#masterframe_passalong.df <- read.csv("C:/Users/Xmanf/Desktop/Ch1 TDR files/passalong2021countmaster_336sec.csv", header=TRUE, stringsAsFactors=FALSE)








#put run #s in an ascending vector
#create vector for number of time the rules were followed to be stored
cum_run_IDS <- unique(masterframe_passalong.df$runIDs)
random_times_pass_along_followed <- c()


#put the number of times the rule was followed into one vector for analysis 
for (j in cum_run_IDS) {
  len_of_passalongs <- length(which(masterframe_passalong.df$rule_followed == "yes" & 
                                        masterframe_passalong.df$runIDs == j))
  
  random_times_pass_along_followed <- c(random_times_pass_along_followed, len_of_passalongs)
}


rand_pass_.frame <- data.frame(random_times_pass_along_followed)

#visualize observed rule follow vs reference distribution
 pass_2021_count_plot <- ggplot(rand_pass_.frame, aes(x=random_times_pass_along_followed)) + 
  geom_histogram(aes(y=..density..),      
                 binwidth=6,
                 colour="black", fill="grey") +
  geom_density() + 
  geom_vline(xintercept = pass_along_real_2021, colour = "red", size = 2) + geom_density(lwd = 1, linetype = 1) + theme_minimal() + theme(axis.text = element_text(size=25), axis.title= element_blank()) +
  scale_x_continuous(name = "Count of Pass-along events", breaks=seq(0, 400, 100)) +  
     coord_cartesian(xlim = c(0, 400), ylim = c(0,.04)) +
scale_y_continuous(breaks = seq(0, .04, .01)) 

pass_2021_count_plot

#calculate p value (proportion of randomized reference values that are more "extreme" than the observed count of rule follows)
pass_along_tally2021 <-length(which(rand_pass_.frame$random_times_pass_along_followed > pass_along_real_2021))

finalpass_along_tally2021 <- 1 -pass_along_tally2021/length(rand_pass_.frame$random_times_pass_along_followed)

#p = 0 for no restriction
#p = .017 for 8 sec
#p = 0 for 85 sec
#p = 0 for 336 sec
                  
```



#Randomzie time between events
```{r}
#Here we are randomizing time between events for the permutation
#start with 
head(pass_along_aggression_list[[1]])

#randomize time between initiation and response between events

pass_along_side_by_side_time <- lapply(pass_along_aggression_list, function(x) mutate(x, actor_2 = lead(actor), 
                                                                                      actor_2_rank = lead(actor_rank), 
                                                                                      subject_2 = lead(subject), 
                                                                                      subject_2_rank = lead(subject_rank), 
                                                                                      full_time_2 = lead(full_time), 
                                                                                      date2 = lead(date))) 






#Loop to detect instances and speed of rule use for the rule in question 
for(i in dateact1) {
  pass_along_side_by_side_time[[i]] <- mutate(pass_along_side_by_side_time[[i]], 
                                              initiated = ifelse(subject == counter, "yes","no"), 
                                              rule_followed = ifelse( subject == actor_2 
                                                                      & date2 == date
                                                                      & subject == counter
                                                                      & actor_2 == counter
                                                                      & actor_2_rank < subject_2_rank
                                                                      & full_time_2 - full_time > 0
                                                                      & actor != subject_2,
                                                                      "yes","no"),
                                              time_to_pass = full_time_2 - full_time)
} 

pass_along_huge_time <- bind_rows(pass_along_side_by_side_time, .id = "column_label")





#Remove duplicate and double counted sequences
pass_along_huge_time <- distinct(pass_along_huge_time, date, full_time, actor, actor_rank, subject, subject_rank, obs_period, date_period, actor_2, subject_2, full_time_2, date2, time_to_pass, .keep_all= TRUE) 



#remove instances of rule use whos speed were calculated to be 0. In this case we cant be certain of which event actually came first
pass_along_huge_time <- filter(pass_along_huge_time, time_to_pass != 0)


date_x <- pass_along_huge_time$date
obs <- pass_along_huge_time$date_period
#separate data into a list with each df=a date so we can randomize within days
#sort_by_date <- function(x, i, y) {y <- filter(x, date == i )
#mutate(y, date_counter = i)}

rule_time_ready_for_rand_list <- list()
dater <- unique(obs)
datex <- c(1: length(unique(obs)))

#loop to create a separate dataframe for each bird that only contains interactions #pertaining to that bird.
#Each dataframe is stored within a list to make the dataframes easy to work with
#separate data into list of each obs session each day 
for(i in datex) { 
  output <- filter(pass_along_huge_time, pass_along_huge_time$date_period == dater[i] )
   if (nrow(output) < 1) {output [ nrow(output) + 1 , ] <- NA
    } 
      rule_time_ready_for_rand_list[[paste0("list", dater[i])]] <- output}









nruns <- 1000

pb = txtProgressBar(min=0, max = nruns, style = 3)

#run ids should be 1 through however many times you want to run through the permutation
runIDs <- seq(1,1000)

#create an empty masterframe to be filled with each run of the permutation
masterframe_passalong.df_time_2021 <- data.frame(runIDs = character(),
                             actor = character(),
                             subject = character(),
                             date = character(),
                             full_time = integer(),
                             counter = character(),
                             actor_2 = character(),
                             subject_2 = character(),
                             full_time_2 = integer(),
                             date2 = character(),
                             initiated = character(),
                             rule_followed = character(),
                             time_to_pass = integer(),
                             date_period = character(),
                             stringsAsFactors=FALSE)


set.seed(150)
#forloop starts here'
for (r in 1:length(runIDs)) { #r = 1 is a test you can uncomment to see if it works before #running it 100 times
#r = 1
  run <- r
      setTxtProgressBar(pb, r) #update progress bar
  loop.run <- paste("run", run) 
  loop.run
  #for example, if r = 1, looprun will say run 1 which will allow you to keep each run's #data straight
  
    

  
  #renamed data
  loop.datalist <- rule_time_ready_for_rand_list
    head(loop.datalist[[3]])
     xorder <- c()
  listlength <- as.numeric(length(loop.datalist))
datex2 <- 1:listlength
  full_time_to_rule <-c()
  loop.data.randomized.time_to_rule.added <- c()
    
    

  for(i in datex2) {
         #store time
     full_time_to_rule[[i]] <- subset(loop.datalist[[i]], select = c(time_to_pass))     
     #remove time from each df in the list. randomizing the order of time wouldnt make sense
     loop.datalist[[i]] <- subset(loop.datalist[[i]], select = -c(time_to_pass))
      #create a randomized sequence of numbers to bind to the subset data (ex. 2,6,1,3,5,4)
      #sort the data frame to put the randomized numbers in order from 1 to whatever and voila, the time between events (speed) has been  randomized (ex. from above 1,2,3,4,5,6)
    xorder[[i]] <- data.frame(xorder = sample(1:length(full_time_to_rule[[i]]$time_to_pass),
                                              length(full_time_to_rule[[i]]$time_to_pass)))
    #bind random order to df
    full_time_to_rule[[i]] <- mutate(full_time_to_rule[[i]], 
                                 xorderx = xorder[[i]]$xorder)
    #put randomized order of numbers in order to randomize speed in the dataset
    full_time_to_rule[[i]] <-
      full_time_to_rule[[i]][order(full_time_to_rule[[i]]$xorderx),]
    #bind time back on
    loop.data.randomized.time_to_rule.added[[i]] <- bind_cols(loop.datalist[[i]], full_time_to_rule[[i]])
    loop.data.randomized.time_to_rule.added[[i]] <- subset(loop.data.randomized.time_to_rule.added[[i]], select = -c(xorderx))

   }
  

  
  
  
  
  
  
  

#combine dataframes into one huge dataframe
loop.datalist_time_randomized_binded_tested_pass_2021 <- bind_rows(loop.data.randomized.time_to_rule.added, .id = "column_label")


 

#sort by time and date
loop.datalist_time_randomized_binded_tested_pass_2021 <- loop.datalist_time_randomized_binded_tested_pass_2021 %>%
  arrange(loop.datalist_time_randomized_binded_tested_pass_2021$date, loop.datalist_time_randomized_binded_tested_pass_2021$full_time)






#Remove duplicate events, events that have been represented twice, and events that could not confidently be counted as the start of passalong
testhugesorted_no_dup_rand_time <- subset(loop.datalist_time_randomized_binded_tested_pass_2021, initiated != "no") 

passalong_no_dup_rand_time <- subset(testhugesorted_no_dup_rand_time, select = c(date, full_time, actor, subject, 
                                                               counter, actor_2, subject_2, full_time_2, date2, 
                                                               initiated,  rule_followed,time_to_pass, date_period))





  
  #end of passalong process
  #end of rule code
  
  
  
  #bind vector of run IDs for each run to the dataframe so that you can have a numeric run #id next to each data point
  #that coresponds with that run which will allow you to sort/put them in ascending order later
 runIDs <- rep(loop.run, length(passalong_no_dup_rand_time$actor))
 
  passalong_complete_rand_time_2021 <- cbind(runIDs, passalong_no_dup_rand_time)
  
  
#put each runs data into teh masterframe
  masterframe_passalong.df_time_2021 <- rbind(masterframe_passalong.df_time_2021, passalong_complete_rand_time_2021)
  
}


#write.csv(masterframe_passalong.df_time_2021, "C:/Users/Xmanf/Desktop/Ch1 TDR files/passalong2021timemaster.csv")

```




#analyze rule speed vs random
```{r}
#masterframe_passalong.df_time_2021 <- read.csv("C:/Users/Xmanf/Desktop/Ch1 TDR files/passalong2021timemaster.csv")

head(masterframe_passalong.df_time_2021)

#subset masterframe so that only rule follows are included
masterframe_passalong.df_time_2021_only_follows <- subset(masterframe_passalong.df_time_2021, rule_followed == "yes" )

#isolate time it takes to carry out rule...
masterframe_passalong_time_sub.df_2021 <- subset( masterframe_passalong.df_time_2021_only_follows, select = c(actor, subject, actor_2,subject_2, time_to_pass,date_period))
head(masterframe_passalong_time_sub.df_2021)



#add data label for the randomized rule speed
masterframe_passalong_time_ready.df <- mutate(masterframe_passalong_time_sub.df_2021, data_type = "randomized")

#ensure that time is numeric
masterframe_passalong_time_ready.df$time_to_pass <- as.numeric(masterframe_passalong_time_ready.df$time_to_pass)


head(pass_length_ready)

#add data label for the observed rule speed
pass_length_ready_label <- mutate(pass_length_ready, data_type = "observed")


#combine df for observed rule speed and randomized rule speed into one df
pass_length_ready_comb <- rbind(masterframe_passalong_time_ready.df, pass_length_ready_label )
unique(pass_length_ready_comb$data_type)




#provide label for rule in question
pass_length_ready_comb <- mutate(pass_length_ready_comb, rule = "passalong")


#make sure that rule speed is numeric
pass_length_ready_comb$time_to_pass <- as.numeric(pass_length_ready_comb$time_to_pass)


#observed vs randomized raw plot. quick look at how the distriubtuions compare
ggplot(pass_length_ready_comb, aes(x=time_to_pass, fill = data_type)) + 
  geom_histogram(aes(y=..density..),      
                 binwidth=1) +#,
                 #colour="black", fill="white") + 
  geom_density() +   scale_x_continuous(name = "length in s of pass events random vs observed", limits = c(0,300)) 


#obtain mode of observed and randomized rule speed for plotting purposes
#getmode <- function(v) {
   #uniqv <- unique(v)
   #uniqv[which.max(tabulate(match(v, uniqv)))]
#}

#pass_2021_mode_obs <- getmode(pass_length_ready_label$time_to_pass)

#pass_2021_mode_rand <-getmode(masterframe_passalong_time_ready.df$time_to_pass)

#bind mode to dfs
#pass_2021_mode <-  rbind(pass_2021_mode_obs,pass_2021_mode_rand)

#test for homogeneity of variance
leveneTest(time_to_pass ~ data_type, data = pass_length_ready_comb)


#split violin plot of observed vs randomized rule speed
pass_violin_plot <- ggplot(pass_length_ready_comb, aes(rule, time_to_pass, fill = data_type))  +
  introdataviz::geom_split_violin(alpha= .9, trim = TRUE, show.legend = FALSE) +
  geom_boxplot(width = .2, alpha = .2, fatten = 2, show.legend = FALSE, outlier.shape = NA) +
  #stat_summary(fun = "mean", geom = "point",  colour = "darkblue", show.legend = F, 
               #position = position_dodge(.200))  +
  scale_x_discrete(name = "Time Dependent Rule") +  
     coord_cartesian(ylim = c(0, 1000)) +
  scale_y_continuous(name = "Speed of passalong events (s)",
                     breaks = seq(0, 1000, 200) 
                     ) + scale_fill_manual(values=c("red","gray")) +
  theme_minimal(base_size = 20)  + theme(axis.text.y = element_text(size=25), axis.title= element_blank(), axis.text.x = element_blank())


pass_2021_time_plot <- pass_violin_plot

pass_2021_time_plot

#calculate the means for observed and randomized rule speed
mean_obs_rand_passalong_2021 <- pass_length_ready_comb %>% group_by(data_type) %>%
  dplyr::summarize (mean(time_to_pass))

mean_obs_rand_passalong_2021
#obs 609.3913
#rand 408.2409

 







```

#Linear model to test observed rule speed vs random
```{r}


#linear mixed model to compare means of observed vs randomized rule speed

m1_pass_2021 <- glmer(time_to_pass ~ data_type  + (1 | date_period)  , data = pass_length_ready_comb ,   control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)), family = Gamma(link = "log"))
summary(m1_pass_2021)
#p = 3.1e-15



#calculate confidence intervals  
confint_pass_2021 <- round(confint(m1_pass_2021, method = "Wald", level = 0.95), 3)
confint_pass_2021
#tukey
summary(glht(m1_pass_2021, linfct = mcp(data_type="Tukey")), test = adjusted("none"))
#find R2 values
tab_model(m1_pass_2021, ci_method="wald")




```

#Earth Movers Distance Calculation
```{r}
#ensure that observed rule speed is numeric
pass_length_ready$time_to_pass <- as.numeric(pass_length_ready$time_to_pass)


head(pass_length_ready)

#convert to a density matrix
#summarize the count of various rule speeds
summary.pass_length_ready <- pass_length_ready %>% group_by(time_to_pass) %>%
  dplyr::summarize (
    count =n())

summary.pass_length_ready

#Add density column
summary.pass_length_ready_density <- mutate(summary.pass_length_ready, density = count/sum(count))
#remove count column
summary.pass_length_ready_density_no_count <- subset(summary.pass_length_ready_density, select = -c(count))
#reorder the columns
summary.pass_length_ready_density_no_count_reordered <- summary.pass_length_ready_density_no_count[, c(2, 1)]
head(summary.pass_length_ready_density_no_count_reordered)
#convert to matrix
summary.pass_length_ready_density_no_count_reordered_mat <- as.matrix(summary.pass_length_ready_density_no_count_reordered)



masterframe_length_ready <- subset(masterframe_passalong_time_sub.df_2021, select = c(time_to_pass))
head(masterframe_length_ready)
#ensure that randomized rule follows are numeric
masterframe_length_ready$time_to_pass <- as.numeric(masterframe_length_ready$time_to_pass)




#convert to a density matrix
#summarize the count of avrious rule speeds
summary.masterframe_length_ready <- masterframe_length_ready %>% group_by(time_to_pass) %>%
  dplyr::summarize (
    count =n())

summary.masterframe_length_ready

#Adddensity column
summary.masterframe_length_ready_density <- mutate(summary.masterframe_length_ready, density = count/sum(count))
#remove count column
summary.masterframe_length_ready_density_no_count <- subset(summary.masterframe_length_ready_density, select = -c(count))
#reorder the columns
summary.masterframe_length_ready_density_no_count_reordered <- summary.masterframe_length_ready_density_no_count[, c(2, 1)]
head(summary.masterframe_length_ready_density_no_count_reordered)
#convert to matrix
summary.masterframe_length_ready_density_no_count_reordered_mat <- as.matrix(summary.masterframe_length_ready_density_no_count_reordered)


#Calculate EMD between observed and randomized rule speed
pass_obs_vs_rand_emd <- emdist::emd(summary.pass_length_ready_density_no_count_reordered_mat, summary.masterframe_length_ready_density_no_count_reordered_mat)
pass_obs_vs_rand_emd
#203.2906

```

```{r}
#####
 qqnorm(pass_length_ready_comb$sqrt_time_to_pass)
qqline(pass_length_ready_comb$sqrt_time_to_pass)

pass_length_ready_comb$log_time_to_pass <- log(pass_length_ready_comb$time_to_pass)
pass_length_ready_comb$sqrt_time_to_pass <- sqrt(pass_length_ready_comb$time_to_pass)
pass_length_ready_comb$cr_time_to_pass <- (pass_length_ready_comb$time_to_pass)^(1/3) 




ggplot(pass_length_ready_comb, aes(x=sqrt_time_to_pass)) + 
  geom_histogram(aes(y=..density..),      
                 binwidth=1) +#,
  #colour="black", fill="white") + 
  geom_density() +   scale_x_continuous(name = "length in s ", limits = c(-5,30))

bf.test(cr_time_to_pass ~ data_type, data = pass_length_ready_comb)
fligner.test(sqrt_time_to_pass ~ data_type, data = pass_length_ready_comb)

leveneTest(sqrt_time_to_pass ~ data_type, data = pass_length_ready_comb)
leveneTest(log_time_to_pass ~ data_type, data = pass_length_ready_comb)



qqnorm(pass_length_ready_comb$cr_time_to_pass)
qqline(pass_length_ready_comb$cr_time_to_pass)



#Lmm 
lm1test <- lmer(log_time_to_pass ~ data_type + (1 | actor_2) + (1 | date_period) , data = pass_length_ready_comb , control = lmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)), REML = TRUE)

qqnorm(resid(test11111))
qqline(resid(test11111))

test11111 <- glm(time_to_pass ~ data_type, data = pass_length_ready_comb, family = Gamma(link = "log") )


sims1 <- simulate(test11111, nsim = 50)
plot(density(pass_length_ready_comb$time_to_pass), 
     main = "Simulated data for gamma model")
for(i in 1:50)lines(density(sims1[[i]]), col="grey80")







m1test <- glmer(cr_time_to_pass ~ data_type + (1 | actor_2) + (1 | date_period) , data = pass_length_ready_comb , control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)), family = Gamma(link = "log"))
summary(m1test)
plot(m1test)


m1glm <- glm(time_to_pass ~ data_type   , data = pass_length_ready_comb,  family = Gamma(link = "log") )

residu<-  residuals(m1)
fit <- fitted(m1)
plot(m1w)
variance <- lm(abs(residu) ~ fit)
variance <- variance$fitted.values^2


Weights <- 1/variance




library(nlme)

mod1.nlme <- nlme::lme(fixed   = time_to_pass ~ data_type,  
                       random  = ~ 1 | actor_2, 
                       weights = varIdent(form = ~ 1 | data_type), 
                       data    = pass_length_ready_comb)





m1w <- glmer(time_to_pass ~ data_type + (1 | actor_2) + (1 | date_period) , data = pass_length_ready_comb , weights = Weights,  control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)), family = Gamma(link = "log"))
summary(m1w)
# p = 1.04e-08



















m1igl <- glmer(time_to_pass ~ data_type + (1 | actor_2) + (1 | date_period) , data = pass_length_ready_comb ,    control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)), family = inverse.gaussian(link = "log"))
summary(m1igl)

m1igl <- glmer(time_to_pass ~ data_type + (1 | actor_2) + (1 | date_period) , data = pass_length_ready_comb ,    control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)), family = inverse.gaussian(link = "log"))

summary(m1igl)











m3 <- glmer(time_to_pass ~ data_type + (1 | actor_2) + (1 | subject_2) , data = pass_length_ready_comb , control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)), family = Gamma(link = "log"))
summary(m3)

residu<-  residuals(m1)
fit <- fitted(m1)
plot(m1w)
variance <- lm(abs(residu) ~ fit)
variance <- variance$fitted.values^2


Weights <- 1/variance
leveneTest(time_to_pass ~ data_type, data = pass_length_ready_comb)


residuig<-  residuals(m1igl )
fitig <- fitted(m1igl)
varianceig <- lm(abs(residu) ~ fit)
varianceig <- varianceig$fitted.values^2


Weightsig <- 1/varianceig




normal_model <- lmer(time_to_pass ~ data_type + (1 | actor_2) + (1 | date_period) , data = pass_length_ready_comb , control = lmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)))


library("DHARMa")
check_gamma_model <- simulateResiduals(fittedModel = m1w, n = 500)
plot(check_gamma_model)

simulationOutput <- simulateResiduals(fittedModel = lm1test, plot = F)
plot(simulationOutput)

residuals(simulationOutput)



m2 <- glmer(time_to_pass ~ data_type + (1 | actor_2) , data = pass_length_ready_comb , control = glmerControl(optimizer = "Nelder_Mead", optCtrl = list(maxfun=2e5)), family = inverse.gaussian(link = "log"))



plot(m1)
qqnorm(resid(m1w))
qqline(resid(m1w))

install.packages("DHARMa")
library(DHARMa)

simout  <-  simulateResiduals(m1,  n=250)
    plotSimulatedResiduals(simout)



unique(test$data_type)
test <- arrange(pass_length_ready_comb,time_to_pass) 
# Conduct Welch's ANOVA
#p-value = 3.077e-12
welch.rules_pass_vs_random <- oneway.test(time_to_pass ~ data_type, data = pass_length_ready_comb, var.equal = FALSE)
welch.rules_pass_vs_random
```

```{r}
#TEST WITH 1 RUN
 masterframe_one_run <- subset( masterframe_passalong.df_time_2021_only_follows, select = c(actor, subject, actor_2, subject_2,time_to_pass, date_period, runIDs))
  
  
masterframe_one_run <- subset(masterframe_one_run, runIDs == "run 1")
masterframe_one_run <- subset( masterframe_one_run, select = c(actor, subject, actor_2, subject_2,time_to_pass, date_period))
masterframe_one_run <- mutate(masterframe_one_run, data_type = "randomized")

pass_length_ready_comb_one <- rbind(masterframe_one_run, pass_length_ready_label )






#COX
#turn categorical variable into numeric form. in this case Observed data = 1 and randomized = 2 dont need to do actually
head(pass_length_ready_comb_one)
  pass_length_ready_comb_ready_for_cox_one <- mutate(pass_length_ready_comb_one,  status = "completed")


#add row to have start status for timesplitter. we remove this row after timesplitter
pass_length_ready_comb_ready_for_cox_xtra_row_one <- rbind(pass_length_ready_comb_ready_for_cox_one, list('DELE', 'DELE', 'DELE', 'DELE', 1, 'DELE', 'DELE', 'incomplete' ))
tail(pass_length_ready_comb_ready_for_cox_xtra_row_one)

pass_row_added_split_2021_one <- timeSplitter(pass_length_ready_comb_ready_for_cox_xtra_row_one,
                        by = 500,
                        event_var = "status",
                        time_var = "time_to_pass",
                        event_start_status = "incomplete"
                        )
  
  
  pass_cox_2021_one <- pass_row_added_split_2021_one %>% filter(row_number() <= n()-1)
tail(pass_cox_2021_one)
  


head(pass_cox_2021_one)

pass_cox_2021_one$interval <- NA



int <- 1



for (i in 1:nrow(pass_cox_2021_one)){ ifelse(pass_cox_2021_one$Start_time[i] == 0, int <- 1, int <- int + 1)
  pass_cox_2021_one$interval[i] <- int
  
}










pass_cox_2021_one <- mutate(pass_cox_2021_one, surv_num = ifelse(status == "completed", 2, 1))





coxme1 <- coxme(Surv(Start_time, Stop_time, status == "completed" ) ~ data_type + (1 | actor_2) + (1 | date_period) , data = pass_cox_2021_one)
coxme1


coxme1split_one <- coxme(Surv(Start_time, Stop_time, status == "completed") ~ data_type + data_type:interval + (1 | actor_2) + (1 | date_period) , data = pass_cox_2021_one)
coxme1split_one

passhmm <- droplevels(pass_cox_2021)


coxphsplit <- coxph(Surv(Start_time, Stop_time, status == "completed") ~ data_type + data_type:Start_time , data = pass_cox_2021_one)

summary(coxphsplit)

cox.zph(coxphsplit)


coxme2 <- coxme(Surv(time_to_pass) ~ data_type + (1 | actor_2)  , data = pass_length_ready_comb_ready_for_cox)
coxme2

coxme3 <- coxme(Surv(time_to_pass) ~ data_type  + (1 | date_period) , data = pass_length_ready_comb_ready_for_cox)
coxme3

coxph1noRE <- coxph(Surv(time_to_pass) ~ data_type  , data = pass_length_ready_comb_ready_for_cox)
coxph1noRE

AIC(coxph1noRE)


anova(coxme1,coxme2)
anova(coxph1noRE, coxme3)


anova(coxph1noRE, coxme1)
plot(cox.zph(coxme1))


cox.zph(coxme1)
cox.zph(coxme2)

```









```{r}

pass_length_ready$time_to_pass <- as.numeric(pass_length_ready$time_to_pass)


head(pass_length_ready)

#convert to a density matrix
summary.pass_length_ready <- pass_length_ready %>% group_by(time_to_pass) %>%
  dplyr::summarize (
    count =n())

summary.pass_length_ready

summary.pass_length_ready_density <- mutate(summary.pass_length_ready, density = count/sum(count))
summary.pass_length_ready_density_no_count <- subset(summary.pass_length_ready_density, select = -c(count))
summary.pass_length_ready_density_no_count_reordered <- summary.pass_length_ready_density_no_count[, c(2, 1)]
head(summary.pass_length_ready_density_no_count_reordered)
summary.pass_length_ready_density_no_count_reordered_mat <- as.matrix(summary.pass_length_ready_density_no_count_reordered)





masterframe_length_ready <- subset(masterframe_passalong_time_sub.df_2021, select = c(time_to_pass))
head(masterframe_length_ready)

#convert to a density matrix
summary.masterframe_length_ready <- masterframe_length_ready %>% group_by(time_to_pass) %>%
  dplyr::summarize (
    count =n())

summary.masterframe_length_ready

summary.masterframe_length_ready_density <- mutate(summary.masterframe_length_ready, density = count/sum(count))
summary.masterframe_length_ready_density_no_count <- subset(summary.masterframe_length_ready_density, select = -c(count))
summary.masterframe_length_ready_density_no_count_reordered <- summary.masterframe_length_ready_density_no_count[, c(2, 1)]
head(summary.masterframe_length_ready_density_no_count_reordered)
summary.masterframe_length_ready_density_no_count_reordered_mat <- as.matrix(summary.masterframe_length_ready_density_no_count_reordered)


#EMD 
pass_obs_vs_rand_emd <- emdist::emd(summary.pass_length_ready_density_no_count_reordered_mat, summary.masterframe_length_ready_density_no_count_reordered_mat)
#203.5295

```

```{r}

pass_length_ready$time_to_pass <- as.numeric(pass_length_ready$time_to_pass)
pass_length_ready$cr_time_to_pass <- (pass_length_ready$time_to_pass)^(1/3) 


head(pass_length_ready)

#convert to a density matrix
summary.pass_length_ready <- pass_length_ready %>% group_by(cr_time_to_pass) %>%
  dplyr::summarize (
    count =n())

summary.pass_length_ready

summary.pass_length_ready_density <- mutate(summary.pass_length_ready, density = count/sum(count))
summary.pass_length_ready_density_no_count <- subset(summary.pass_length_ready_density, select = -c(count))
summary.pass_length_ready_density_no_count_reordered <- summary.pass_length_ready_density_no_count[, c(2, 1)]
head(summary.pass_length_ready_density_no_count_reordered)
summary.pass_length_ready_density_no_count_reordered_mat <- as.matrix(summary.pass_length_ready_density_no_count_reordered)





masterframe_length_ready_emd <- subset(masterframe_passalong_time_sub.df_2021, select = c(time_to_pass))
head(masterframe_length_ready_emd)
masterframe_length_ready_emd$cr_time_to_pass <- (masterframe_length_ready_emd$time_to_pass)^(1/3)

#convert to a density matrix
summary.masterframe_length_ready_emd <- masterframe_length_ready_emd %>% group_by(cr_time_to_pass) %>%
  dplyr::summarize (
    count =n())

summary.masterframe_length_ready_emd

summary.masterframe_length_ready_density <- mutate(summary.masterframe_length_ready_emd, density = count/sum(count))
summary.masterframe_length_ready_density_no_count <- subset(summary.masterframe_length_ready_density, select = -c(count))
summary.masterframe_length_ready_density_no_count_reordered <- summary.masterframe_length_ready_density_no_count[, c(2, 1)]
head(summary.masterframe_length_ready_density_no_count_reordered)
summary.masterframe_length_ready_density_no_count_reordered_mat <- as.matrix(summary.masterframe_length_ready_density_no_count_reordered)


#EMD 
pass_obs_vs_rand_emd_cr <- emdist::emd(summary.pass_length_ready_density_no_count_reordered_mat, summary.masterframe_length_ready_density_no_count_reordered_mat)
#1.6366
```

```{r}
#emd test
A. <- matrix(c(1:6 / sum(1:6), 1,2,4,5,8,9), 6)

B. <- matrix(c(.23,.1,.05,.411,.18,.029, 7,10,4,5,3,1), nrow = 6, ncol = 2)
C. <- matrix(c(.23,.1,.05,.411,.18,.029, 8,10,4,5,3,1), nrow = 6, ncol = 2)
D. <- matrix(c(.23,.1,.05,.411,.18,.029, 70,15,47,53,32,19), nrow = 6, ncol = 2)
E. <- matrix(c(.23,.1,.05,.411,.09,.09,.029, 7,10,4,5,3,1,11), nrow = 7, ncol = 2)

emdist::emd(A., B.)
emdist::emd(B., C.)
emdist::emd(B., D.)
emdist::emd(B., E.)


```



















```{r}


#COX
#turn categorical variable into numeric form. in this case Observed data = 1 and randomized = 2 dont need to do actually
head(pass_length_ready_comb)
  pass_length_ready_comb_ready_for_cox <- mutate(pass_length_ready_comb,  status = "completed")
pass_length_ready_comb_ready_for_cox <- subset(pass_length_ready_comb_ready_for_cox, select = -c(rule))

#add row to have start status for timesplitter. we remove this row after timesplitter
pass_length_ready_comb_ready_for_cox_xtra_row <- rbind(pass_length_ready_comb_ready_for_cox, list('DELE', 'DELE', 'DELE', 'DELE', 1, 'DELE', 'DELE', 'incomplete' ))
tail(pass_length_ready_comb_ready_for_cox_xtra_row)

pass_row_added_split_2021 <- timeSplitter(pass_length_ready_comb_ready_for_cox_xtra_row,
                        by = 500,
                        event_var = "status",
                        time_var = "time_to_pass",
                        event_start_status = "incomplete"
                        )
  
  
  pass_cox_2021 <- pass_row_added_split_2021 %>% filter(row_number() <= n()-1)
tail(pass_cox_2021)
  


head(pass_cox_2021)

pass_cox_2021$interval <- NA



int <- 1



for (i in 1:nrow(pass_cox_2021)){ ifelse(pass_cox_2021$Start_time[i] == 0, int <- 1, int <- int + 1)
  pass_cox_2021$interval[i] <- int
  
}







#TRY ADDING INTERVALS WITH THE LOOP AND N +1 THINGY


pass_cox_2021 <- mutate(pass_cox_2021, surv_num = ifelse(status == "completed", 1, 0))

pass_length_ready_comb_ready_for_cox <- mutate(pass_length_ready_comb_ready_for_cox, surv_num = ifelse(status == "completed", 1, 0))

testting <- arrange(pass_length_ready_comb_ready_for_cox, actor_2, time_to_pass)


coxme1 <- coxme(Surv(time_to_pass) ~ data_type + (1|actor_2) + (1 | date_period) , data = pass_length_ready_comb_ready_for_cox)
coxme1


coxme1split <- coxme(Surv(Start_time, Stop_time, surv_num) ~ data_type + data_type:Start_time + (1 | actor_2) + (1 | date_period) , data = pass_cox_2021)
coxme1split

passhmm <- droplevels(pass_cox_2021)


coxphsplit <- coxph(Surv(Start_time, Stop_time, surv_num) ~ data_type + data_type:Start_time , data = pass_cox_2021)

summary(coxphsplit)

cox.zph(coxph1noRE)


coxme2 <- coxme(Surv(time_to_pass) ~ data_type + (1 | actor_2)  , data = pass_length_ready_comb_ready_for_cox)
coxme2

coxme3 <- coxme(Surv(time_to_pass) ~ data_type  + (1 | date_period) , data = pass_length_ready_comb_ready_for_cox)
coxme3

coxph1noRE <- coxph(Surv(time_to_pass) ~ data_type + cluster(actor_2), method = "breslow",   data = pass_length_ready_comb_ready_for_cox)
coxph1noRE

AIC(coxph1noRE)


anova(coxme1,coxme2)
anova(coxph1noRE, coxme3)


anova(coxph1noRE, coxme1)
plot(cox.zph(coxme1))


cox.zph(coxme1)
cox.zph(coxme2)


install.packages("MuMIn") 
library(MuMIn)
#dredge

#blurg <- subset(model, subset = delta<2)
#model.avg(blurg)
#summary of that










coxme4 <- coxme(Surv(time_to_pass) ~ data_type + (1 | actor_2) + (1 | date_period) + (1 | actor) + (1 | subject_2) + (1 | subject_2) , data = pass_length_ready_comb_ready_for_cox)










 
coxmetest <- coxme(Surv(time_to_pass) ~ data_type + (1 | actor_2/data_type) + (1 | date_period) , data = pass_length_ready_comb_ready_for_cox)
coxmetest

anova(coxme1)
plot(predict(coxme1),residuals(coxme1, type = "martingale") , 
     xlab = "fitted values", ylab = "martingale residuals" , 
     main = "residual plot", las = 1)

abline(h=0)
lines(smooth.spline(predict(coxme1),
                     residuals(coxme1, type = "martingale")), col = "red")



   control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)), family = Gamma(link = "log"))

  
  

  
  
  
  masterframe_one_run <- subset( masterframe_passalong.df_time_2021_only_follows, select = c(actor, subject, actor_2, subject_2,time_to_pass, date_period, runIDs))
  
  
masterframe_one_run <- mutate(masterframe_one_run, data_type = "randomized")
masterframe_one_run <- subset(masterframe_one_run, runIDs == "run 1")
masterframe_one_run <- subset( masterframe_one_run, select = c(actor, subject, actor_2, subject_2,time_to_pass, date_period))
pass_length_ready_comb_one <- rbind(masterframe_one_run, pass_length_ready_label )


hmm <- coxme(Surv(time_to_pass) ~ data_type + (1 | actor_2) + (1 | date_period) , data = pass_length_ready_comb_one)
hmm








```


