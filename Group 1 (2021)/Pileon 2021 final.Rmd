---
title: "Pileon 2021 final"
author: "Xavier Francis"
date: "2024-03-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




#Load packages
```{r}
library(readr)
library(dplyr)
library(tidyr)
library(data.table) 
library(ggplot2)
library(chemodiv)
library(introdataviz)
library(lme4)
library(multcomp)
library(sjPlot)
library(emdist)


```


#Determine observed number of pile ons
```{r}

#start with both_numbered_sorted

#ensure that ranks are numeric
both_numbered_sorted$actor_rank <- as.numeric(both_numbered_sorted$actor_rank)
both_numbered_sorted$subject_rank <- as.numeric(both_numbered_sorted$subject_rank)

head(both_numbered_sorted)


#procedure to add obs session

#store the first row as a separate df. It will be binded back on later 
row_1_obs <- both_numbered_sorted[1,]

#put events side by side. This will allow us to subtract consecutive times from one another to determine whether an event took place on a separate observation session. 
obs_period_pt_1 <- mutate(both_numbered_sorted, actor_2 = lead(actor),
actor_2_rank = lead(actor_rank), 
subject_2 = lead(subject),                                   
subject_2_rank = lead(subject_rank), 
 full_time_2 = lead(full_time), 
date2 = lead(date))

#add empty columns for observation period and date period
obs_period_pt_1$obs_period <- NA
obs_period_pt_1$date_period <- NA

#create ticker for loop
q <- 1

#loop to calculate observation sessions. If consecutive events were on the same day but there was a long time between events, it is determined that the 2nd event took place in a separate observation session. The ticker goes up, and is reset if events took place on different days.
for (i in 1:nrow(obs_period_pt_1)) {ifelse(obs_period_pt_1$date[i] == obs_period_pt_1$date2[i]
                                            & obs_period_pt_1$full_time_2[i] - obs_period_pt_1$full_time[i] >= 1800, q <- q+1, q <- q)
  ifelse(obs_period_pt_1$date[i] != obs_period_pt_1$date2[i], q <- 1, q <- q)
  obs_period_pt_1$obs_period [i] <- q
  }

#remove original columns and keep mutated columns. These will replace original columns
obs_period_pt_2 <- subset(obs_period_pt_1, select = c(date2,  full_time_2, actor_2, actor_2_rank, subject_2, subject_2_rank, obs_period, date_period  ))

#get rid of the bottom, which will be full of NAs, as the last event in the original data does not have anything that comes after
obs_period_pt_3 <- slice(obs_period_pt_2, 1:(n() - 1))

#rename mutated columns with original names 
setnames(obs_period_pt_3, old = c('date2',  'full_time_2', 'actor_2', 'actor_2_rank', 'subject_2', 'subject_2_rank'), 
         new = c('date',  'full_time', 'actor', 'actor_rank', 'subject', 'subject_rank'))

#add observation period "1" onto first row that we subseted off, as the first event in the data has to take place in obs session 1
row_1_obs$obs_period <- 1 
row_1_obs$date_period <- NA

#ensure that row 1 matches the df
row_1_obs_ready <-  subset(row_1_obs, select = c(date,  full_time, actor, actor_rank, subject, subject_rank, obs_period, date_period  ))

#bind first row and df together
obs_period_pt_4 <- rbind(row_1_obs_ready, obs_period_pt_3)
#add date period 
obs_period_pt_4$date_period <- paste(obs_period_pt_4$date,obs_period_pt_4$obs_period)
head(obs_period_pt_4)

date_x <- obs_period_pt_4$date
obs <- obs_period_pt_4$date_period
#separate data into a list with each df=a date 

datelist__pile <- list()

dater <- unique(obs)
datex <- c(1: length(unique(obs)))
actex <- c(1:length(actor))


#separate data into list of each obs session each day for each obs
for(i in datex) { 
  output <- filter(obs_period_pt_4, obs_period_pt_4$date_period == dater[i])
  datelist__pile[[i]] <- output}




#ensure df arranged by date and time
datelist__pile <- lapply(datelist__pile, function(x) arrange(x, date, full_time))


#put events sidebyside within date and within obs
datelist__pile_2021 <- lapply(datelist__pile, function(x) mutate(x, actor_2 = lead(actor), subject_2 = lead(subject), 
                                                                         full_time_2 = lead(full_time), actor_2_rank = lead(actor_rank), subject_2_rank = lead(subject_rank), date2 = lead(date)))


#pick out pile on rule while keeping all dataframes in a list 
pile_side_by_side_tested_2021 <- map(datelist__pile_2021, ~ mutate(.x, initiated = "yes", 
                                      rule_followed = ifelse( subject == subject_2
                                                              & actor != actor_2
                                                              & full_time_2 - full_time <= 336 
                                                              & full_time_2 - full_time > 0
                                                              & date2 == date,
                                                              "yes","no")))


 #combine dataframes into one huge dataframe
 pile_huge_2021 <- bind_rows(pile_side_by_side_tested_2021, .id = "column_label")
 
 #sort by time and date
 pile_huge_2021_sorted <- pile_huge_2021 %>%
   arrange(pile_huge_2021$date, pile_huge_2021$full_time)
 
#Remove duplicate events, events that have been represented twice, and events that could not confidently be counted as the start of pileon 
 pile_huge_2021_sorted_no_dupr <- subset(pile_huge_2021_sorted, initiated != "no") 
 
 #subset for desired columns
 pile_no_dupr <- subset(pile_huge_2021_sorted_no_dupr, select = c(date, full_time, actor, actor_rank, subject, subject_rank, 
                                                                         actor_2, actor_2_rank, subject_2, subject_2_rank, full_time_2, date2, 
                                                                         initiated, rule_followed))
 
 table(pile_no_dupr$rule_followed)
 
 
 #determine how many times rule was followed
 pile_real_2021 <- length(which(pile_no_dupr$rule_followed == "yes"))
 pile_real.frame_2021 <- data.frame(pile_real_2021)

 
 #create df of only rule follows
 pile_doner_all_yes_2021 <-filter(pile_no_dupr, rule_followed == "yes")


# pile 199
 # opp-pile 33


```






#test for individual rule following
```{r}

#test for individual use
unique(pile_doner_all_yes_2021$actor_2)

summary.pile.individ_2021 <- pile_doner_all_yes_2021 %>% group_by(actor_2) %>%
  summarize (
    count =n())

summary.pile.individ_2021





#compare to raw dataset to see if any birds didnt use rule at all
unique(t2021_aggression_only_ready$actor)
unique(t2021_aggression_only_ready$subject)





#Calculate richness score for rule following
pile_richness <- length(summary.pile.individ_2021$actor_2)/length((unique(t2021_aggression_only_ready$actor)
))

pile_for_even <- subset(summary.pile.individ_2021, select = c(count))

final_pile_for_even <- as.data.frame(t(pile_for_even))

pile_even_value <-calcDiv(final_pile_for_even, type = "PielouEven", q = 1) 

pile_even_value


# Plot
individ_pile_plot_2021 <- ggplot(summary.pile.individ_2021, aes(x = actor_2, y = count )) + 
  geom_bar(stat = "identity", width = 0.6) + # Consistent bar width
scale_y_continuous( breaks = seq(0, 60, 2)) + 
  theme_minimal()  +
  theme(
    axis.text.x = element_text(angle = 90, vjust=0.5),
    axis.title.x = element_text( face = "bold",  margin = margin(t = 15)),  # X-axis title
    axis.title.y = element_text( face = "bold",  margin = margin(r = 15)),
    ) +
  labs(
    x = "Parakeet ID",  # Add your custom x-axis title here
    y = "Count of rule follows"   # Add your custom y-axis title here
  )

individ_pile_plot_2021
#Calculate eveness metric
pile_for_even <- subset(summary.pile.individ_2021, select = c(count))

final_pile_for_even <- as.data.frame(t(pile_for_even))

pile_even_value <-calcDiv(final_pile_for_even, type = "PielouEven", q = 1) 

pile_even_value

```


#test for rule speed
```{r}

#########################################################################################################
#test for length of pile on
head(datelist__pile_2021[[1]])


#follows similar procedure as calculating the count of rule follows, with some differences in the rule detection loop and the structure

#test for length of pileons in seconds
pile_side_by_side_tested_time_2021 <- map(datelist__pile_2021, ~ mutate(.x, initiated = "yes", 
                                      rule_followed = ifelse( subject == subject_2
                                                              & actor != actor_2
                                                              & full_time_2 - full_time > 0
                                                              & date2 == date,
                                                              "yes","no"), time_to_pile = full_time_2 - full_time))




 #combine dataframes into one huge dataframe
 pile_huge_time_2021 <- bind_rows(pile_side_by_side_tested_time_2021, .id = "column_label")
 
 #sort by time and date
 pile_huge_time_2021_sorted <- pile_huge_time_2021 %>%
   arrange(pile_huge_time_2021$date, pile_huge_time_2021$full_time)
 
#remove any duplicate or double counted events 
 pile_huge_time_2021_sorted_no_dupr <- subset(pile_huge_time_2021_sorted, initiated != "no") 
 
 #subset for columns of interest
 pile_huge_time_2021_sorted_no_dupr <- subset(pile_huge_time_2021_sorted_no_dupr, select = c(date, full_time, actor, actor_rank, subject, subject_rank, 
                                                                         actor_2, actor_2_rank, subject_2, subject_2_rank, full_time_2, date2, 
                                                                         initiated, rule_followed, time_to_pile, date_period))
 




#get df where rule was followed
pile_length_2021 <- subset(pile_huge_time_2021_sorted_no_dupr, rule_followed != "no")


#subset for columns of interest
pile_length_ready_2021 <- subset( pile_length_2021, select = c(time_to_pile, actor, subject, actor_2, subject_2, date_period))

pi <- length(pile_length_ready_2021$time_to_pile)


#summarize the speed of rule follows. Here we are checking whether the speed of the rule in question tends to be clustered
summary.pile <- pile_length_ready_2021 %>% group_by(time_to_pile) %>%
  summarize (
    count =n())


summary.pile

#mean rule speedmean(pile_length_ready_2021$time_to_pile)
# pile 46.98817 
 # opp-pile 25.12121 

#quick glimpses of the distribution of rule speeds
ggplot(pile_length_ready_2021, aes(x=time_to_pile)) + 
  geom_histogram(aes(y=..density..),      
                 binwidth=50,
                 colour="black", fill="white") + 
  geom_density()


ggplot(pile_length_ready_2021, aes(x=time_to_pile)) + 
  geom_histogram(aes(y=..density..),      
                 binwidth=10,
                 colour="black", fill="white") + 
  geom_density() +  scale_x_continuous(name = "length in s of pile on events", limits = c(0,3000)) 


```


#IGNORE. MEANT FOR SOME EXPLORATORY ANALYSIS
```{r}


 mean(pile_length_ready_2021_rank_down_2021$time_to_pile)
#pile 46.98817     
#opp pile   25.12121 


 
 

 mean_pile_speed_rank_down_2021.df <- mutate(pile_length_ready_2021_rank_down_2021, rule = "pile")
 
  mean_opp_pile_speed_2021.df <- mutate(pile_length_ready_2021_opp_pile_2021, rule = "opp_pile")

 mean_pile_opp_pile_comb_2021 <- rbind(mean_pile_speed_rank_down_2021.df, mean_opp_pile_speed_2021.df)
 
 mean_pile_opp_pile_comb_2021$time_to_pile <- as.numeric(mean_pile_opp_pile_comb_2021$time_to_pile)
 
 mean_pile_opp_pile_comb_model_2021  <- glmer(time_to_pile ~ rule  + (1 | date_period)    , data = mean_pile_opp_pile_comb_2021  , control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)), family = Gamma(link = "log"))
summary(mean_pile_opp_pile_comb_model_2021)
 #p =  0.186       
```



#Permutation to randomize order of events
```{r}


#################################################loop#################################################################

head(both_numbered_sorted)


#procedure to randomize within obs sesh
#store first row
row_1_obs <- both_numbered_sorted[1,]

#put events side by side. This will allow us to subtract consecutive times from one another to determine whether an event took place on a separate observation session.
obs_period_pt_1 <- mutate(both_numbered_sorted, actor_2 = lead(actor),
                          actor_2_rank = lead(actor_rank), 
                          subject_2 = lead(subject),                                   
                          subject_2_rank = lead(subject_rank), 
                          full_time_2 = lead(full_time), 
                          date2 = lead(date))


#add empty columns for observation period and date period
obs_period_pt_1$obs_period <- NA
obs_period_pt_1$date_period <- NA

#create ticker for loop
q <- 1

#loop to calculate observation sessions. If consecutive events were on the same day but there was a long time between events, it is determined that the 2nd event took place in a separate observation session. The ticker goes up, and is reset if events took place on different days.
for (i in 1:nrow(obs_period_pt_1)) {ifelse(obs_period_pt_1$date[i] == obs_period_pt_1$date2[i]
                                           & obs_period_pt_1$full_time_2[i] - obs_period_pt_1$full_time[i] >= 1800, q <- q+1, q <- q)
  ifelse(obs_period_pt_1$date[i] != obs_period_pt_1$date2[i], q <- 1, q <- q)
  obs_period_pt_1$obs_period [i] <- q
}

#remove original columns and keep mutated columns. These will replace original columns
obs_period_pt_2 <- subset(obs_period_pt_1, select = c(date2,  full_time_2, actor_2, actor_2_rank, subject_2, subject_2_rank, obs_period, date_period  ))
#get rid of the bottom, which will be full of NAs, as the last event in the original data does not have anything that comes after
obs_period_pt_3 <- slice(obs_period_pt_2, 1:(n() - 1))

#rename mutated columns with original names 
setnames(obs_period_pt_3, old = c('date2',  'full_time_2', 'actor_2', 'actor_2_rank', 'subject_2', 'subject_2_rank'), 
         new = c('date',  'full_time', 'actor', 'actor_rank', 'subject', 'subject_rank'))

#add observation period "1" onto first row that we subseted off, as the first event in the data has to take place in obs session 1
row_1_obs$obs_period <- 1 
row_1_obs$date_period <- NA

#ensure that row 1 matches the df
row_1_obs_ready <-  subset(row_1_obs, select = c(date,  full_time, actor, actor_rank, subject, subject_rank, obs_period, date_period  ))

#bind first row and df together
obs_period_pt_4 <- rbind(row_1_obs_ready, obs_period_pt_3)

#add date period 
obs_period_pt_4$date_period <- paste(obs_period_pt_4$date,obs_period_pt_4$obs_period)


head(obs_period_pt_4)

obs <- obs_period_pt_4$date_period

#separate data into a list with each df=a date period so we can randomize within days and obs periods
datelist__pile <- list()

dater <- unique(obs)
datex <- c(1: length(unique(obs)))
actex <- c(1:length(actor))

#loop to create a separate dataframe for of each obs session each day 
#Each dataframe is stored within a list to make the dataframes easy to work with
#We wish to conserve our permutation randomization within days and, more specifically, within observation sessions
for(i in datex) { 
  output <- filter(obs_period_pt_4, obs_period_pt_4$date_period == dater[i])
  datelist__pile[[i]] <- output}








#run ids should be 1 through however many times you want to run through the permutation
runIDs <- seq(1,1000)

#create an empty masterframe to be filled with each run of the permutation
masterframe_pileon.df <- data.frame(runIDs = character(),
                                         actor = character(),
                                         subject = character(),
                                         date = character(),
                                         full_time = integer(),
                                         actor_2 = character(),
                                         subject_2 = character(),
                                         full_time_2 = integer(),
                                         date2 = character(),
                                         initiated = character(),
                                         rule_followed = character(),
                                         stringsAsFactors=FALSE)


nruns <- 1000
#add progress bar
pb <- txtProgressBar(min=0, max = nruns, style = 3)
#seed = 2 for no restriction
#seed = 583 for 8 sec
#seed = 701 for 85 seconds
#seed = 8 for 336 seconds

#set seed
set.seed(8)
#forloop starts here'
for (r in 1:length(runIDs)) { #r = 1 is a test you can uncomment to see if it works before #running it 100 times
  #r = 1
  run <- r
  setTxtProgressBar(pb, r) #update progress bar

  loop.run <- paste("run", run) 
  loop.run
  #for example, if r = 1, looprun will say run 1 which will allow you to keep each run's #data straight
  
  
  #loop.seed <- set.seed[r] didnt work so ignore. not needed
  
  
  #renamed data
  loop.datalist <- datelist__pile
  head(loop.datalist[[3]])
  xorder <- c()
  listlength <- as.numeric(length(loop.datalist))
  datex2 <- 1:listlength
  full_time_list <-c()
  loop.data.randomized.time.added <- c()
  #get rid of anything thats not actor and receiver (we will bind back on the date and time #later anyways to preserve
  #their order)
  


   for(i in datex2) {
     #store time
     full_time_list[[i]] <- subset(loop.datalist[[i]], select = c(full_time))
     #remove time from each df in the list. randomizing the order of time wouldnt make sense
     loop.datalist[[i]] <- subset(loop.datalist[[i]], select = -c(full_time))

      #create a randomized sequence of numbers to bind to the subset data (ex. 2,6,1,3,5,4)
      #sort the data frame to put the randomized numbers in order from 1 to whatever and voila, the order of events has been randomized (ex.  from above 1,2,3,4,5,6)
    xorder[[i]] <- data.frame(xorder = sample(1:length(loop.datalist[[i]]$actor),
                                              length(loop.datalist[[i]]$actor)))
    #bind random order to df
    loop.datalist[[i]] <- mutate(loop.datalist[[i]], 
                                 xorderx = xorder[[i]]$xorder)
    #put randomized order of numbers in order to randomize rows in the dataset
    loop.datalist[[i]] <-
      loop.datalist[[i]][order(loop.datalist[[i]]$xorderx),]
    #bind time back on
    loop.data.randomized.time.added[[i]] <- bind_cols(loop.datalist[[i]], full_time_list[[i]])
    loop.data.randomized.time.added[[i]] <- subset(loop.data.randomized.time.added[[i]], select = -c(xorderx))

   }
  
  #order data by time and date
  loop.data.randomized.time.added <- lapply(loop.data.randomized.time.added, function(x) arrange(x, date, full_time))

  
  #rename data
  shuffled_day_obs_list <- loop.data.randomized.time.added
  
  
  

#put events sidebyside within date and within obs
datelist__pile_2021_rand <- lapply(shuffled_day_obs_list, function(x) mutate(x, actor_2 = lead(actor), subject_2 = lead(subject), 
                                                                         full_time_2 = lead(full_time), actor_2_rank = lead(actor_rank), subject_2_rank = lead(subject_rank), date2 = lead(date)))


#pick out pile on rule while keeping all dataframes in a list 
pile_side_by_side_tested_2021_rand <- map(datelist__pile_2021_rand, ~ mutate(.x, initiated = "yes", 
                                      rule_followed = ifelse( subject == subject_2
                                                              & actor != actor_2
                                                              & full_time_2 - full_time <= 336 
                                                              & full_time_2 - full_time > 0
                                                              & date2 == date,
                                                              "yes","no")))




  
  
  
   #combine dataframes into one huge dataframe
   pile_huge_2021 <- bind_rows(pile_side_by_side_tested_2021_rand, .id = "column_label")
   
   #sort by time and date
   pile_huge_2021_sorted <- pile_huge_2021 %>%
     arrange(pile_huge_2021$date, pile_huge_2021$full_time)
   
   
   
   
   
   #Remove duplicate events, events that have been represented twice, and events that could not confidently be counted as the start of pileon
   pile_huge_2021_sorted_no_dupr <- subset(pile_huge_2021_sorted, initiated != "no") 
  
  
  #subset for desired columns
  pile_on_almost_complete <- subset(pile_huge_2021_sorted_no_dupr, select = c(actor, subject, date, full_time, 
                                                                     actor_2, subject_2, full_time_2, date2, 
                                                                     initiated, rule_followed))
  
  
  #bind vector of run IDs for each run to the dataframe so that you can have a numeric run #id next to each data point
  #that coresponds with that run which will allow you to sort/put them in ascending order later
  runIDs <- rep(loop.run, length(pile_on_almost_complete$actor))
  
  pile_on_complete <- cbind(runIDs, pile_on_almost_complete)
  
  masterframe_pileon.df <- rbind(masterframe_pileon.df, pile_on_complete)
}

  
#######################################################LOOP#END#######################################################
#write.csv(masterframe_pileon.df, "C:/Users/Xmanf/Desktop/Ch1 TDR files/pileon2021countmaster_336sec.csv")



```


```{r}



#masterframe_pileon.df <- read.csv("C:/Users/Xmanf/Desktop/Ch1 TDR files/pileon2021countmaster_336sec.csv", header=TRUE, stringsAsFactors=FALSE)




#put run #s in an ascending vector
#create vector for number of time the rules were followed to be stored
cum_run_IDS <- unique(masterframe_pileon.df$runIDs)
random_times_pile_on_followed <- c()


#put the number of times the rule was followed into one vector for analysis 
for (j in cum_run_IDS) {
  len_of_pileons <- length(which(masterframe_pileon.df$rule_followed == "yes" & 
                                      masterframe_pileon.df$runIDs == j))
  
  random_times_pile_on_followed <- c(random_times_pile_on_followed, len_of_pileons)
}


rand_pile_.frame <- data.frame(random_times_pile_on_followed)

#visualize observed rule follow vs reference distribution
pile_2021_count_plot <- ggplot(rand_pile_.frame, aes(x=random_times_pile_on_followed)) + 
  geom_histogram(aes(y=..density..),      
                 binwidth=6,
                 colour="black", fill="grey") + 
  geom_vline(xintercept = pile_real_2021, colour = "red", size = 2)  +
  geom_density(lwd = 1, linetype = 1) + theme_minimal() + theme(axis.text = element_text(size=25), axis.title= element_blank()) +
  scale_x_continuous(name = "Count of Pile-on events", breaks=seq(0, 200, 50)) +  
     coord_cartesian(xlim = c(0, 200), ylim = c(0,.04)) +
scale_y_continuous(breaks = seq(0, .04, .01)) 

pile_2021_count_plot
   
#calculate p value (proportion of randomized reference values that are more "extreme" than the observed count of rule follows)
pile_tally2021 <-length(which(rand_pile_.frame$random_times_pile_on_followed < pile_real_2021))

finalpile_tally2021 <- 1-  pile_tally2021/length(rand_pile_.frame$random_times_pile_on_followed)

#p=0 for no restriction
#p = 0 for 8 sec
#p = 0for 85 sec
#p = 0 for 336 sec









```


#randomize rule speed

```{r}
#randomize time between initiation and response between events

#Loop to detect instances and speed of rule use for the rule in question 
pile_side_by_side_tested_time_2021 <- map(datelist__pile_2021, ~ mutate(.x, initiated = "yes", 
                                      rule_followed = ifelse( subject == subject_2
                                                              & actor != actor_2
                                                              & full_time_2 - full_time > 0
                                                              & date2 == date,
                                                              "yes","no"), time_to_pile = full_time_2 - full_time))








#mark true pile ons 
pile_side_by_side_tested_time_2021_marked <- map(pile_side_by_side_tested_time_2021, ~ mutate(.x, t.o.f = ifelse(rule_followed == "yes", "true","false")))

pile_side_by_side_tested_time_2021_marked_sub <- c()

#remove mutated columns
for (i in datex){
  pile_side_by_side_tested_time_2021_marked_sub[[i]] <- subset(pile_side_by_side_tested_time_2021_marked[[i]], select = -c(actor_2, subject_2, actor_2_rank, subject_2_rank, full_time_2, date2, initiated, rule_followed ) )
}





#separate data into list of each obs session each day for each bird
actorer <- actor
actex <- c(1:length(actor))
dater <- unique(obs)
list_split_by_bird_time <- c()

for(i in datex2) {
for (g in actex) {output <- subset(pile_side_by_side_tested_time_2021_marked_sub[[i]], actor == actorer[g] |  subject == actorer[g])
   if (nrow(output) < 1) {output [ nrow(output) + 1 , ] <- NA
    } 
  output <- mutate(output, counter = actorer[g])
  list_split_by_bird_time[[paste0("list", dater[i], actorer[g])]] <- output
}}

 
  #arrange by time and date
list_split_by_bird_time <- lapply(list_split_by_bird_time, function(x) arrange(x, date, full_time))


   #put events side by side
   pile_time_by_side_2021 <- lapply(list_split_by_bird_time, function(x) mutate(x, actor_2 = lead(actor), 
                                                                                    actor_2_rank = lead(actor_rank), 
                                                                                    subject_2 = lead(subject), 
                                                                                    subject_2_rank = lead(subject_rank), 
                                                                                    full_time_2 = lead(full_time), 
                                                                                    date2 = lead(date)))


   
   pile_time_by_side_2021<- pile_time_by_side_2021 [sapply(pile_time_by_side_2021, nrow)>0]


  
#pick out true pile on rule while keeping all dataframes in a list and calculating speed
pile_time_by_side_tested_2021 <- map(pile_time_by_side_2021, ~ mutate(.x, initiated = ifelse( subject == counter, "yes","no"), 
                                      rule_followed = ifelse( subject == subject_2
                                                              & actor != actor_2
                                                              & full_time_2 - full_time > 0
                                                              & date2 == date
                                                              & subject == counter
                                                              & subject_2 == counter
                                                              & t.o.f == "true",
                                                              "yes","no"), time_to_pile = full_time_2 - full_time))

 #remove NAs
  pile_time_by_side_tested_2021_no_na <- lapply(pile_time_by_side_tested_2021, function(x) na.omit(x))
   
   
pilelisttimelength2021 <- as.numeric(length(pile_time_by_side_tested_2021_no_na))
datex3 <- 1:pilelisttimelength2021  
  
    #split into df for each obs session
for (i in datex3) {
  pile_time_by_side_tested_2021_no_na[[i]]$time_to_pile <- as.numeric(pile_time_by_side_tested_2021_no_na[[i]]$time_to_pile)
  
}




#Bind list of dfs into one df
pile_side_by_side_tested_time_2021_binded <- bind_rows(pile_time_by_side_tested_2021_no_na)


#Remove duplicate and double counted sequences
pile_side_by_side_tested_time_2021_binded <- distinct(pile_side_by_side_tested_time_2021_binded, date, full_time, actor, actor_rank, subject, subject_rank, obs_period, date_period, actor_2, subject_2, full_time_2, date2, time_to_pile, .keep_all= TRUE) 



#remove instances of rule use whos speed were calculated to be 0. In this case we cant be certain of which event actually came first
pile_side_by_side_tested_time_2021_binded <- filter(pile_side_by_side_tested_time_2021_binded, time_to_pile != 0)


date_x <- pile_side_by_side_tested_time_2021_binded$date
obs <- pile_side_by_side_tested_time_2021_binded$date_period
#separate data into a list with each df=a date so we can randomize within days
#sort_by_date <- function(x, i, y) {y <- filter(x, date == i )
#mutate(y, date_counter = i)}

pile_side_by_side_tested_time_2021_list <- list()
dater <- unique(obs)
datex <- c(1: length(unique(obs)))
#boop <- filter(both_numbered_sorted, both_numbered_sorted$date == datex [2])

#loop to create a separate dataframe for each bird that only contains interactions #pertaining to that bird.
#Each dataframe is stored within a list to make the dataframes easy to work with
#separate data into list of each obs session each day 
for(i in datex) { 
  output <- filter(pile_side_by_side_tested_time_2021_binded, pile_side_by_side_tested_time_2021_binded$date_period == dater[i] )
   if (nrow(output) < 1) {output [ nrow(output) + 1 , ] <- NA
    } 
      pile_side_by_side_tested_time_2021_list[[paste0("list", dater[i])]] <- output}





nruns <- 1000

pb = txtProgressBar(min=0, max = nruns, style = 3)

#run ids should be 1 through however many times you want to run through the permutation
runIDs <- seq(1,1000)

#create an empty masterframe to be filled with each run of the permutation
masterframe_pileon.df_time_2021 <- data.frame(runIDs = character(),
                             actor = character(),
                             subject = character(),
                             date = character(),
                             full_time = integer(),
                             counter = character(),
                             actor_2 = character(),
                             subject_2 = character(),
                             full_time_2 = integer(),
                             date2 = character(),
                             initiated = character(),
                             rule_followed = character(),
                             time_to_pile = integer(),
                            date_period = character(),
                             stringsAsFactors=FALSE)


set.seed(18)
#forloop starts here'
for (r in 1:length(runIDs)) { #r = 1 is a test you can uncomment to see if it works before #running it 100 times
#r = 1
  run <- r
      setTxtProgressBar(pb, r) #update progress bar
  loop.run <- paste("run", run) 
  loop.run
  #for example, if r = 1, looprun will say run 1 which will allow you to keep each run's #data straight
  
    

  
  #renamed data
  loop.datalist <- pile_side_by_side_tested_time_2021_list
    head(loop.datalist[[3]])
    xorder <- c()
  listlength <- as.numeric(length(loop.datalist))
datex2 <- 1:listlength
  full_time_to_rule <-c()
  loop.data.randomized.time_to_rule.added <- c()
    
    

  for(i in datex2) {
         #store time
     full_time_to_rule[[i]] <- subset(loop.datalist[[i]], select = c(time_to_pile))     
     #remove time from each df in the list. randomizing the order of time wouldnt make sense
     loop.datalist[[i]] <- subset(loop.datalist[[i]], select = -c(time_to_pile))
      #create a randomized sequence of numbers to bind to the subset data (ex. 2,6,1,3,5,4)
      #sort the data frame to put the randomized numbers in order from 1 to whatever and voila, the time between events (speed) has been  randomized (ex. from above 1,2,3,4,5,6)
    xorder[[i]] <- data.frame(xorder = sample(1:length(full_time_to_rule[[i]]$time_to_pile),
                                              length(full_time_to_rule[[i]]$time_to_pile)))
    #bind random order to df
    full_time_to_rule[[i]] <- mutate(full_time_to_rule[[i]], 
                                 xorderx = xorder[[i]]$xorder)
    #put randomized order of numbers in order to randomize speed in the dataset
    full_time_to_rule[[i]] <-
      full_time_to_rule[[i]][order(full_time_to_rule[[i]]$xorderx),]
    #bind time back on
    loop.data.randomized.time_to_rule.added[[i]] <- bind_cols(loop.datalist[[i]], full_time_to_rule[[i]])
    loop.data.randomized.time_to_rule.added[[i]] <- subset(loop.data.randomized.time_to_rule.added[[i]], select = -c(xorderx))

   }
  

  
  
  
  
  
  
  

#combine dataframes into one huge dataframe
loop.datalist_time_randomized_binded_tested_pile_2021 <- bind_rows(loop.data.randomized.time_to_rule.added, .id = "column_label")


 

#sort by time and date
loop.datalist_time_randomized_binded_tested_pile_2021 <- loop.datalist_time_randomized_binded_tested_pile_2021 %>%
  arrange(loop.datalist_time_randomized_binded_tested_pile_2021$date, loop.datalist_time_randomized_binded_tested_pile_2021$full_time)






#Remove duplicate events, events that have been represented twice, and events that could not confidently be counted as the start of pileon
testhugesorted_no_dup_rand_time <- subset(loop.datalist_time_randomized_binded_tested_pile_2021, initiated != "no") 

pileon_no_dup_rand_time <- subset(testhugesorted_no_dup_rand_time, select = c(date, full_time, actor, subject, 
                                                               counter, actor_2, subject_2, full_time_2, date2, 
                                                               initiated,  rule_followed,time_to_pile, date_period))





  
  #end of pileon process
  #end of rule code
  
  
  
  #bind vector of run IDs for each run to the dataframe so that you can have a numeric run #id next to each data point
  #that coresponds with that run which will allow you to sort/put them in ascending order later
 runIDs <- rep(loop.run, length(pileon_no_dup_rand_time$actor))
 
  pileon_complete_rand_time_2021 <- cbind(runIDs, pileon_no_dup_rand_time)
  
  
#put each runs data into teh masterframe
  masterframe_pileon.df_time_2021 <- rbind(masterframe_pileon.df_time_2021, pileon_complete_rand_time_2021)
  
}





#write.csv(masterframe_pileon.df_time_2021, "C:/Users/Xmanf/Desktop/Ch1 TDR files/pile2021timemaster.csv")
```










#analyze observed rule speed vs random

```{r}

#masterframe_pileon.df_time_2021 <- read.csv("C:/Users/Xmanf/Desktop/Ch1 TDR files/pile2021timemaster.csv")
#raw data 

head(masterframe_pileon.df_time_2021)

#subset masterframe so that only rule follows are included
masterframe_pileon.df_time_2021_only_follows <- subset(masterframe_pileon.df_time_2021, rule_followed == "yes" )

#isolate time it takes to carry out rule...
masterframe_pileon_time_sub.df_2021 <- subset( masterframe_pileon.df_time_2021_only_follows, select = c(actor, subject, actor_2,subject_2, time_to_pile,date_period))
head(masterframe_pileon_time_sub.df_2021)



#add data label for the randomized rule speed
masterframe_pileon_time_ready.df <- mutate(masterframe_pileon_time_sub.df_2021, data_type = "randomized")

#ensure that time is numeric
masterframe_pileon_time_ready.df$time_to_pile <- as.numeric(masterframe_pileon_time_ready.df$time_to_pile)


head(pile_length_ready_2021)

#add data label for the observed rule speed
pile_length_ready_2021_label <- mutate(pile_length_ready_2021, data_type = "observed")


#combine df for observed rule speed and randomized rule speed into one df
pile_length_ready_2021_comb <- rbind(masterframe_pileon_time_ready.df, pile_length_ready_2021_label )
unique(pile_length_ready_2021_comb$data_type)




#provide label for rule in question
pile_length_ready_2021_comb <- mutate(pile_length_ready_2021_comb, rule = "pileon")


#make sure that rule speed is numeric
pile_length_ready_2021_comb$time_to_pile <- as.numeric(pile_length_ready_2021_comb$time_to_pile)


#observed vs randomized raw plot. quick look at how the distriubtuions compare
ggplot(pile_length_ready_2021_comb, aes(x=time_to_pile, fill = data_type)) + 
  geom_histogram(aes(y=..density..),      
                 binwidth=1) +#,
                 #colour="black", fill="white") + 
  geom_density() +   scale_x_continuous(name = "length in s of pile events random vs observed", limits = c(0,300)) 


#obtain mode of observed and randomized rule speed for plotting purposes
#getmode <- function(v) {
   #uniqv <- unique(v)
   #uniqv[which.max(tabulate(match(v, uniqv)))]
#}

#pile_2021_mode_obs <- getmode(pile_length_ready_2021_label$time_to_pile)

#pile_2021_mode_rand <-getmode(masterframe_pileon_time_ready.df$time_to_pile)

#bind mode to dfs
#pile_2021_mode <-  rbind(pile_2021_mode_obs,pile_2021_mode_rand)

#test for homogeneity of variance
leveneTest(time_to_pile ~ data_type, data = pile_length_ready_2021_comb)


#split violin plot of observed vs randomized rule speed
pile_violin_plot <- ggplot(pile_length_ready_2021_comb, aes(rule, time_to_pile, fill = data_type))  +
  introdataviz::geom_split_violin(alpha= .9, trim = TRUE, show.legend = FALSE) +
  geom_boxplot(width = .2, alpha = .2, fatten = 2, show.legend = FALSE, outlier.shape = NA) +
  #stat_summary(fun = "mean", geom = "point",  colour = "darkblue", show.legend = F, 
               #position = position_dodge(.200))  +
  scale_x_discrete(name = "Time Dependent Rule") +  
     coord_cartesian(ylim = c(0, 1000)) +
  scale_y_continuous(name = "Speed of pileon events (s)",
                     breaks = seq(0, 1000, 200) 
                     ) + scale_fill_manual(values=c("red","gray")) +
  theme_minimal(base_size = 20)  + theme(axis.text.y = element_text(size=25), axis.title= element_blank(), axis.text.x = element_blank())


pile_2021_time_plot <- pile_violin_plot

pile_2021_time_plot

#calculate the means for observed and randomized rule speed
mean_obs_rand_pileon_2021 <- pile_length_ready_2021_comb %>% group_by(data_type) %>%
  dplyr::summarize (mean(time_to_pile))

mean_obs_rand_pileon_2021
#obs 43.41584
#rand 420.61725


#linear mixed model to compare means of observed vs randomized rule speed

m1pile <- glmer(time_to_pile ~ data_type  + (1 | date_period)  , data = pile_length_ready_2021_comb ,   control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)), family = Gamma(link = "log"))
summary(m1pile)
#p is 2e-16 


m1pile2021 <- m1pile
#calculate confidence intervals  
confint_pile_2021 <- round(confint(m1pile2021, method = "Wald", level = 0.95), 3)
confint_pile_2021
#tukey
summary(glht(m1pile2021, linfct = mcp(data_type="Tukey")), test = adjusted("none"))
#find R2 value
tab_model(m1pile2021)




```

#Earth Movers Distance Calculation

```{r}
#ensure that observed rule speed is numeric
pile_length_ready_2021$time_to_pile <- as.numeric(pile_length_ready_2021$time_to_pile)


head(pile_length_ready_2021)

#convert to a density matrix
#summarize the count of various rule speeds

summary.pile_length_ready_2021 <- pile_length_ready_2021 %>% group_by(time_to_pile) %>%
  dplyr::summarize (
    count =n())

summary.pile_length_ready_2021
#Add density column
summary.pile_length_ready_2021_density <- mutate(summary.pile_length_ready_2021, density = count/sum(count))
#remove count column
summary.pile_length_ready_2021_density_no_count <- subset(summary.pile_length_ready_2021_density, select = -c(count))
#reorder the columns
summary.pile_length_ready_2021_density_no_count_reordered <- summary.pile_length_ready_2021_density_no_count[, c(2, 1)]
head(summary.pile_length_ready_2021_density_no_count_reordered)
#convert to matrix
summary.pile_length_ready_2021_density_no_count_reordered_mat <- as.matrix(summary.pile_length_ready_2021_density_no_count_reordered)





masterframe_length_ready <- subset(masterframe_pileon_time_sub.df_2021, select = c(time_to_pile))
head(masterframe_length_ready)

#convert to a density matrix
#summarize the count of various rule speeds

summary.masterframe_length_ready <- masterframe_length_ready %>% group_by(time_to_pile) %>%
  dplyr::summarize (
    count =n())

summary.masterframe_length_ready

#Adddensity column
summary.masterframe_length_ready_density <- mutate(summary.masterframe_length_ready, density = count/sum(count))
#remove count column
summary.masterframe_length_ready_density_no_count <- subset(summary.masterframe_length_ready_density, select = -c(count))
#reorder the columns
summary.masterframe_length_ready_density_no_count_reordered <- summary.masterframe_length_ready_density_no_count[, c(2, 1)]
head(summary.masterframe_length_ready_density_no_count_reordered)
#convert to matrix
summary.masterframe_length_ready_density_no_count_reordered_mat <- as.matrix(summary.masterframe_length_ready_density_no_count_reordered)


#Calculate EMD between observed and randomized rule speed
pile_obs_vs_rand_emd <- emdist::emd(summary.pile_length_ready_2021_density_no_count_reordered_mat, summary.masterframe_length_ready_density_no_count_reordered_mat)
pile_obs_vs_rand_emd
#377.2015

```



















































#SCRAP
```{r}


#get individual ids for actor, subject, actor_2, and subject_2 in format for multi membership model
pile_mm_pt1 <- pile_length_ready_2021
pile_mm_pt1$act_sub_comb <- paste0(pile_mm_pt1$actor, ",", pile_mm_pt1$subject, ",",  pile_mm_pt1$actor_2, ",", pile_mm_pt1$subject_2)

pile_length_ready_2021_comb_2021_mm <- lmerMultiMember::weights_from_vector(pile_mm_pt1$act_sub_comb)



m1pile_2021_MM <- glmer(time_to_pile ~ data_type   + (1| date_period) + ( 1| individ_ID), data = pile_length_ready_2021 ,   control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=2e5)), family = Gamma(link = "log"), memberships = list(individ_ID = pile_length_ready_2021_comb_2021_mm))

summary(m1pile_2021_MM)

















#install.packages("DHARMa")
library(DHARMa)
check_gamma_model <- simulateResiduals(fittedModel = m1pile, n = 500)
plot(check_gamma_model)















 m1pile <- glm(time_to_pile ~ data_type   , data = pile_length_ready_2021 ,    family = Gamma("log"))

summary(m1pile)

```






```{r}

#Here we are randomizing time between events for the permutation
#start with 
head(datelist__pile_2021[[1]])




#pick out pile on rule while keeping all dataframes in a list (yay!!!)
pile_side_by_side_tested_time_2021 <- map(datelist__pile_2021, ~ mutate(.x, initiated = "yes", 
                                      rule_followed = ifelse( subject == subject_2
                                                              & actor != actor_2
                                                              & full_time_2 - full_time > 0
                                                              & date2 == date,
                                                              "yes","no")))
#mark true pile ons 
pile_side_by_side_tested_time_2021_marked <- map(pile_side_by_side_tested_time_2021, ~ mutate(.x, t.o.f = ifelse(rule_followed == "yes", "true","false")))

pile_side_by_side_tested_time_2021_marked_sub <- c()

for (i in datex){
  pile_side_by_side_tested_time_2021_marked_sub[[i]] <- subset(pile_side_by_side_tested_time_2021_marked[[i]], select = -c(actor_2, subject_2, actor_2_rank, subject_2_rank, full_time_2, date2, initiated, rule_followed ) )
}



#separate data into list of each obs session each day for each bird
actorer <- actor
actex <- c(1:length(actor))
dater <- unique(obs)
list_split_by_bird_time <- c()

for(i in datex2) {
for (g in actex) {output <- subset(pile_side_by_side_tested_time_2021_marked_sub[[i]], actor == actorer[g] |  subject == actorer[g])
   if (nrow(output) < 1) {output [ nrow(output) + 1 , ] <- NA
    } 
  output <- mutate(output, counter = actorer[g])
  list_split_by_bird_time[[paste0("list", dater[i], actorer[g])]] <- output
}}

 
  
list_split_by_bird_time <- lapply(list_split_by_bird_time, function(x) arrange(x, date, full_time))


   #put events side by side
   pile_time_by_side_2021 <- lapply(list_split_by_bird_time, function(x) mutate(x, actor_2 = lead(actor), 
                                                                                    actor_2_rank = lead(actor_rank), 
                                                                                    subject_2 = lead(subject), 
                                                                                    subject_2_rank = lead(subject_rank), 
                                                                                    full_time_2 = lead(full_time), 
                                                                                    date2 = lead(date)))


   
   pile_time_by_side_2021<- pile_time_by_side_2021 [sapply(pile_time_by_side_2021, nrow)>0]


  
#pick out true pile on rule while keeping all dataframes in a list and calc time
pile_time_by_side_tested_2021 <- map(pile_time_by_side_2021, ~ mutate(.x, initiated = ifelse( subject == counter, "yes","no"), 
                                      rule_followed = ifelse( subject == subject_2
                                                              & actor != actor_2
                                                              & full_time_2 - full_time > 0
                                                              & date2 == date
                                                              & subject == counter
                                                              & subject_2 == counter
                                                              & t.o.f == "true",
                                                              "yes","no"), time_to_pile = full_time_2 - full_time))

 
  pile_time_by_side_tested_2021_no_na <- lapply(pile_time_by_side_tested_2021, function(x) na.omit(x))
   
   
pilelisttimelength2021 <- as.numeric(length(pile_time_by_side_tested_2021_no_na))
datex3 <- 1:pilelisttimelength2021  
  
  
for (i in datex3) {
  pile_time_by_side_tested_2021_no_na[[i]]$time_to_pile <- as.numeric(pile_time_by_side_tested_2021_no_na[[i]]$time_to_pile)
  
}



pb = txtProgressBar(min=0, max = nruns, style = 3)

#run ids should be 1 through however many times you want to run through the permutation
runIDs <- seq(1,1000)

#create an empty masterframe to be filled with each run of the permutation
masterframe_pileon.df_time_2021 <- data.frame(runIDs = character(),
                             actor = character(),
                             subject = character(),
                             date = character(),
                             full_time = integer(),
                             counter = character(),
                             actor_2 = character(),
                             subject_2 = character(),
                             full_time_2 = integer(),
                             date2 = character(),
                             initiated = character(),
                             rule_followed = character(),
                             time_to_pile = integer(),
                             stringsAsFactors=FALSE)


set.seed(850)
#forloop starts here'
for (r in 1:length(runIDs)) { #r = 1 is a test you can uncomment to see if it works before #running it 100 times
#r = 1
  run <- r
      setTxtProgressBar(pb, r) #update progress bar
  loop.run <- paste("run", run) 
  loop.run
  #for example, if r = 1, looprun will say run 1 which will allow you to keep each run's #data straight
  
 
  
  #renamed data
  loop.datalist <- pile_time_by_side_tested_2021_no_na
  head(loop.datalist[[3]])
  xorder <- c()
  listlength <- as.numeric(length(loop.datalist))
datex2 <- 1:listlength
  full_time_to_rule_list <-c()
  loop.data.randomized.time_to_rule.added <- c()
  #get rid of anything thats not actor and receiver (we will bind back on the date and time #later anyways to preserve
  #their order)
  
#remove date from each df in the list
#create a randomized sequence of numbers to bind to the subset data (ex. 2,6,1,3,5,4)
#sort the data frame to put the randomized numbers in order from 1 to whatever and voila, #the order of events has been randomized (ex. from above 1,2,3,4,5,6)

   for(i in datex2) {
     full_time_to_rule_list[[i]] <- subset(loop.datalist[[i]], select = c(time_to_pile))
         loop.datalist[[i]] <- subset(loop.datalist[[i]], select = -c(time_to_pile))

    xorder[[i]] <- data.frame(xorder = sample(1:length(full_time_to_rule_list[[i]]$time_to_pile),
                                              length(full_time_to_rule_list[[i]]$time_to_pile)))
    full_time_to_rule_list[[i]] <- mutate(full_time_to_rule_list[[i]], 
                                 xorderx = xorder[[i]]$xorder)
    full_time_to_rule_list[[i]] <-
      full_time_to_rule_list[[i]][order(full_time_to_rule_list[[i]]$xorderx),]
    #bind time back on
    loop.data.randomized.time_to_rule.added[[i]] <- bind_cols(loop.datalist[[i]], full_time_to_rule_list[[i]])
    loop.data.randomized.time_to_rule.added[[i]] <- subset(loop.data.randomized.time_to_rule.added[[i]], select = -c(xorderx))

   }
  

loop.data.randomized.time_to_rule.added_ordered <- lapply(loop.data.randomized.time_to_rule.added, function(x) arrange(x, date, full_time))
   

#combine dataframes into one huge dataframe
loop.datalist_time_randomized_binded_tested_pile_2021 <- bind_rows(loop.data.randomized.time_to_rule.added_ordered, .id = "column_label")

#sort by time and date
loop.datalist_time_randomized_binded_tested_pile_2021 <- loop.datalist_time_randomized_binded_tested_pile_2021 %>%
  arrange(loop.datalist_time_randomized_binded_tested_pile_2021$date, loop.datalist_time_randomized_binded_tested_pile_2021$full_time)






#need to check but i think it works to get rid of all "initiated no" rows to get rid of #duplicates, as pile 
#is literally possible whenever an aggressive event takes place
#Update. It does work

testhugesorted_no_dup_rand_time <- subset(loop.datalist_time_randomized_binded_tested_pile_2021, initiated != "no") 

pile_no_dup_rand_time <- subset(testhugesorted_no_dup_rand_time, select = c(date, full_time, actor, subject, 
                                                               counter, actor_2, subject_2, full_time_2, date2, 
                                                               initiated,  rule_followed,time_to_pile))





  
  #end of pile process
  #end of rule code
  
  
  
  #bind vector of run IDs for each run to the dataframe so that you can have a numeric run #id next to each data point
  #that coresponds with that run which will allow you to sort/put them in ascending order later
 runIDs <- rep(loop.run, length(pile_no_dup_rand_time$actor))
 
  pile_complete_rand_time_2021 <- cbind(runIDs, pile_no_dup_rand_time)
  
  
#put each runs data into teh masterframe
  masterframe_pileon.df_time_2021 <- rbind(masterframe_pileon.df_time_2021, pile_complete_rand_time_2021)
  
}

  
```
